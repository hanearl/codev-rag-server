# Task 05-B: ì™¸ë¶€ ì„œë¹„ìŠ¤ í´ë¼ì´ì–¸íŠ¸ êµ¬í˜„

## ğŸ¯ ëª©í‘œ
RAG ì„œë²„ì—ì„œ ì‚¬ìš©í•  ì™¸ë¶€ ì„œë¹„ìŠ¤(Embedding Server, LLM Server, Vector DB) í´ë¼ì´ì–¸íŠ¸ë¥¼ TDD ë°©ì‹ìœ¼ë¡œ êµ¬í˜„í•©ë‹ˆë‹¤.

## ğŸ“‹ MVP ë²”ìœ„
- Embedding Server HTTP í´ë¼ì´ì–¸íŠ¸
- LLM Server HTTP í´ë¼ì´ì–¸íŠ¸  
- Vector DB (Qdrant) í´ë¼ì´ì–¸íŠ¸
- ì—°ê²° ì•ˆì •ì„± ë° ì—ëŸ¬ ì²˜ë¦¬
- ì¬ì‹œë„ ë¡œì§ êµ¬í˜„

## ğŸ—ï¸ ê¸°ìˆ  ìŠ¤íƒ
- **HTTP í´ë¼ì´ì–¸íŠ¸**: httpx (ë¹„ë™ê¸°)
- **ë²¡í„° DB**: qdrant-client
- **ì„¤ì • ê´€ë¦¬**: pydantic-settings
- **í…ŒìŠ¤íŠ¸**: pytest, pytest-asyncio, httpx

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
rag-server/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ clients.py          â† ì™¸ë¶€ ì„œë¹„ìŠ¤ í´ë¼ì´ì–¸íŠ¸ (ìƒˆë¡œ ì¶”ê°€)
â”‚   â”‚   â”œâ”€â”€ config.py           â† ì„¤ì • ê´€ë¦¬ (ì—…ë°ì´íŠ¸ í•„ìš”)
â”‚   â”‚   â””â”€â”€ exceptions.py       â† ì»¤ìŠ¤í…€ ì˜ˆì™¸ (ìƒˆë¡œ ì¶”ê°€)
â”‚   â”œâ”€â”€ features/               â† ê¸°ì¡´ ì¡´ì¬
â”‚   â”œâ”€â”€ db/                     â† ê¸°ì¡´ ì¡´ì¬
â”‚   â”œâ”€â”€ main.py                 â† ê¸°ì¡´ ì¡´ì¬
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ unit/
â”‚       â””â”€â”€ core/
â”‚           â”œâ”€â”€ __init__.py
â”‚           â””â”€â”€ test_clients.py  â† í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸ (ìƒˆë¡œ ì¶”ê°€)
â”œâ”€â”€ requirements.txt            â† ì—…ë°ì´íŠ¸ í•„ìš”
â””â”€â”€ pytest.ini                 â† ìƒˆë¡œ ì¶”ê°€
```

## ğŸ§ª TDD êµ¬í˜„ ìˆœì„œ

### 1ë‹¨ê³„: ì„¤ì • ë° ì˜ˆì™¸ í´ë˜ìŠ¤ ì •ì˜

```python
# app/core/config.py
from pydantic import BaseSettings

class Settings(BaseSettings):
    embedding_server_url: str = "http://localhost:8001"
    llm_server_url: str = "http://localhost:8002"
    qdrant_host: str = "localhost"
    qdrant_port: int = 6333
    request_timeout: int = 30
    max_retries: int = 3
    
    class Config:
        env_file = ".env"

# app/core/exceptions.py
class ExternalServiceError(Exception):
    """ì™¸ë¶€ ì„œë¹„ìŠ¤ í˜¸ì¶œ ì˜¤ë¥˜"""
    pass

class EmbeddingServiceError(ExternalServiceError):
    """ì„ë² ë”© ì„œë¹„ìŠ¤ ì˜¤ë¥˜"""
    pass

class LLMServiceError(ExternalServiceError):
    """LLM ì„œë¹„ìŠ¤ ì˜¤ë¥˜"""
    pass

class VectorDBError(ExternalServiceError):
    """ë²¡í„° DB ì˜¤ë¥˜"""
    pass
```

### 2ë‹¨ê³„: Embedding í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸ (TDD)

**ğŸ”´ í…ŒìŠ¤íŠ¸ ì‘ì„±**
```python
# tests/unit/core/test_clients.py
import pytest
from unittest.mock import AsyncMock, patch, Mock
import httpx
from app.core.clients import EmbeddingClient, LLMClient, VectorClient
from app.core.exceptions import EmbeddingServiceError

@pytest.mark.asyncio
async def test_embedding_client_should_call_single_embedding():
    """ì„ë² ë”© í´ë¼ì´ì–¸íŠ¸ê°€ ë‹¨ì¼ í…ìŠ¤íŠ¸ ì„ë² ë”©ì„ í˜¸ì¶œí•´ì•¼ í•¨"""
    # Given
    with patch('httpx.AsyncClient') as mock_client:
        mock_response = AsyncMock()
        mock_response.json.return_value = {
            "embedding": [0.1, 0.2, 0.3],
            "text": "test text"
        }
        mock_response.status_code = 200
        mock_client.return_value.__aenter__.return_value.post.return_value = mock_response
        
        client = EmbeddingClient("http://localhost:8001")
        
        # When
        result = await client.embed_single({"text": "test text"})
        
        # Then
        assert result["embedding"] == [0.1, 0.2, 0.3]
        mock_client.return_value.__aenter__.return_value.post.assert_called_once_with(
            "http://localhost:8001/api/v1/embed",
            json={"text": "test text"},
            timeout=30.0
        )

@pytest.mark.asyncio
async def test_embedding_client_should_call_bulk_embedding():
    """ì„ë² ë”© í´ë¼ì´ì–¸íŠ¸ê°€ ë²Œí¬ í…ìŠ¤íŠ¸ ì„ë² ë”©ì„ í˜¸ì¶œí•´ì•¼ í•¨"""
    # Given
    with patch('httpx.AsyncClient') as mock_client:
        mock_response = AsyncMock()
        mock_response.json.return_value = {
            "embeddings": [
                {"embedding": [0.1, 0.2, 0.3]},
                {"embedding": [0.4, 0.5, 0.6]}
            ],
            "count": 2
        }
        mock_response.status_code = 200
        mock_client.return_value.__aenter__.return_value.post.return_value = mock_response
        
        client = EmbeddingClient("http://localhost:8001")
        
        # When
        result = await client.embed_bulk({"texts": ["text1", "text2"]})
        
        # Then
        assert len(result["embeddings"]) == 2
        assert result["count"] == 2

@pytest.mark.asyncio
async def test_embedding_client_should_handle_http_error():
    """ì„ë² ë”© í´ë¼ì´ì–¸íŠ¸ê°€ HTTP ì˜¤ë¥˜ë¥¼ ì²˜ë¦¬í•´ì•¼ í•¨"""
    # Given
    with patch('httpx.AsyncClient') as mock_client:
        mock_response = AsyncMock()
        mock_response.status_code = 500
        mock_response.raise_for_status.side_effect = httpx.HTTPStatusError(
            "Server Error", request=Mock(), response=mock_response
        )
        mock_client.return_value.__aenter__.return_value.post.return_value = mock_response
        
        client = EmbeddingClient("http://localhost:8001")
        
        # When & Then
        with pytest.raises(EmbeddingServiceError):
            await client.embed_single({"text": "test"})

@pytest.mark.asyncio
async def test_embedding_client_should_retry_on_failure():
    """ì„ë² ë”© í´ë¼ì´ì–¸íŠ¸ê°€ ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„í•´ì•¼ í•¨"""
    # Given
    with patch('httpx.AsyncClient') as mock_client:
        # ì²« ë²ˆì§¸ í˜¸ì¶œì€ ì‹¤íŒ¨, ë‘ ë²ˆì§¸ í˜¸ì¶œì€ ì„±ê³µ
        mock_success_response = AsyncMock()
        mock_success_response.json.return_value = {"embedding": [0.1, 0.2, 0.3]}
        mock_success_response.status_code = 200
        
        mock_fail_response = AsyncMock()
        mock_fail_response.status_code = 503
        mock_fail_response.raise_for_status.side_effect = httpx.HTTPStatusError(
            "Service Unavailable", request=Mock(), response=mock_fail_response
        )
        
        mock_client.return_value.__aenter__.return_value.post.side_effect = [
            mock_fail_response,
            mock_success_response
        ]
        
        client = EmbeddingClient("http://localhost:8001", max_retries=2)
        
        # When
        result = await client.embed_single({"text": "test"})
        
        # Then
        assert result["embedding"] == [0.1, 0.2, 0.3]
        assert mock_client.return_value.__aenter__.return_value.post.call_count == 2
```

**ğŸŸ¢ ìµœì†Œ êµ¬í˜„**
```python
# app/core/clients.py
import httpx
import asyncio
from typing import Dict, Any, List, Optional
from qdrant_client import QdrantClient, AsyncQdrantClient
from qdrant_client.models import PointStruct, Filter, FieldCondition
import uuid
from datetime import datetime
import logging
from .exceptions import EmbeddingServiceError, LLMServiceError, VectorDBError

logger = logging.getLogger(__name__)

class EmbeddingClient:
    def __init__(self, base_url: str, timeout: float = 30.0, max_retries: int = 3):
        self.base_url = base_url.rstrip('/')
        self.timeout = timeout
        self.max_retries = max_retries
    
    async def embed_single(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """ë‹¨ì¼ í…ìŠ¤íŠ¸ ì„ë² ë”©"""
        url = f"{self.base_url}/api/v1/embed"
        return await self._make_request("POST", url, json=request)
    
    async def embed_bulk(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """ë²Œí¬ í…ìŠ¤íŠ¸ ì„ë² ë”©"""
        url = f"{self.base_url}/api/v1/embed/bulk"
        return await self._make_request("POST", url, json=request)
    
    async def _make_request(self, method: str, url: str, **kwargs) -> Dict[str, Any]:
        """HTTP ìš”ì²­ ë° ì¬ì‹œë„ ë¡œì§"""
        last_exception = None
        
        for attempt in range(self.max_retries + 1):
            try:
                async with httpx.AsyncClient() as client:
                    response = await client.request(
                        method, url, timeout=self.timeout, **kwargs
                    )
                    response.raise_for_status()
                    return response.json()
            
            except httpx.HTTPStatusError as e:
                last_exception = e
                if e.response.status_code < 500:
                    # 4xx ì—ëŸ¬ëŠ” ì¬ì‹œë„í•˜ì§€ ì•ŠìŒ
                    break
                if attempt < self.max_retries:
                    await asyncio.sleep(2 ** attempt)  # ì§€ìˆ˜ ë°±ì˜¤í”„
            
            except (httpx.RequestError, asyncio.TimeoutError) as e:
                last_exception = e
                if attempt < self.max_retries:
                    await asyncio.sleep(2 ** attempt)
        
        logger.error(f"Embedding ì„œë¹„ìŠ¤ ìš”ì²­ ì‹¤íŒ¨: {last_exception}")
        raise EmbeddingServiceError(f"ìš”ì²­ ì‹¤íŒ¨: {last_exception}")

class LLMClient:
    def __init__(self, base_url: str, timeout: float = 60.0, max_retries: int = 3):
        self.base_url = base_url.rstrip('/')
        self.timeout = timeout
        self.max_retries = max_retries
    
    async def chat_completion(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """ì±„íŒ… ì™„ì„± ìš”ì²­ (OpenAI í˜¸í™˜)"""
        url = f"{self.base_url}/v1/chat/completions"
        return await self._make_request("POST", url, json=request)
    
    async def _make_request(self, method: str, url: str, **kwargs) -> Dict[str, Any]:
        """HTTP ìš”ì²­ ë° ì¬ì‹œë„ ë¡œì§"""
        last_exception = None
        
        for attempt in range(self.max_retries + 1):
            try:
                async with httpx.AsyncClient() as client:
                    response = await client.request(
                        method, url, timeout=self.timeout, **kwargs
                    )
                    response.raise_for_status()
                    return response.json()
            
            except httpx.HTTPStatusError as e:
                last_exception = e
                if e.response.status_code < 500:
                    break
                if attempt < self.max_retries:
                    await asyncio.sleep(2 ** attempt)
            
            except (httpx.RequestError, asyncio.TimeoutError) as e:
                last_exception = e
                if attempt < self.max_retries:
                    await asyncio.sleep(2 ** attempt)
        
        logger.error(f"LLM ì„œë¹„ìŠ¤ ìš”ì²­ ì‹¤íŒ¨: {last_exception}")
        raise LLMServiceError(f"ìš”ì²­ ì‹¤íŒ¨: {last_exception}")

class VectorClient:
    def __init__(self, host: str = "localhost", port: int = 6333):
        self.host = host
        self.port = port
        self.client = QdrantClient(host=host, port=port)
    
    def create_collection(self, collection_name: str, vector_size: int) -> bool:
        """ì»¬ë ‰ì…˜ ìƒì„±"""
        try:
            from qdrant_client.models import VectorParams, Distance
            
            self.client.create_collection(
                collection_name=collection_name,
                vectors_config=VectorParams(
                    size=vector_size,
                    distance=Distance.COSINE
                )
            )
            return True
        except Exception as e:
            logger.error(f"ì»¬ë ‰ì…˜ ìƒì„± ì‹¤íŒ¨: {e}")
            raise VectorDBError(f"ì»¬ë ‰ì…˜ ìƒì„± ì‹¤íŒ¨: {e}")
    
    def insert_code_embedding(self, collection_name: str, 
                             embedding: List[float], metadata: Dict[str, Any]) -> str:
        """ì½”ë“œ ì„ë² ë”© ì‚½ì…"""
        try:
            point_id = str(uuid.uuid4())
            
            point = PointStruct(
                id=point_id,
                vector=embedding,
                payload=metadata
            )
            
            self.client.upsert(
                collection_name=collection_name,
                points=[point]
            )
            
            return point_id
        except Exception as e:
            logger.error(f"ì„ë² ë”© ì‚½ì… ì‹¤íŒ¨: {e}")
            raise VectorDBError(f"ì„ë² ë”© ì‚½ì… ì‹¤íŒ¨: {e}")
    
    def delete_by_file_path(self, collection_name: str, file_path: str) -> int:
        """íŒŒì¼ ê²½ë¡œë¡œ ì„ë² ë”© ì‚­ì œ"""
        try:
            result = self.client.delete(
                collection_name=collection_name,
                points_selector=Filter(
                    must=[
                        FieldCondition(
                            key="file_path",
                            match={"value": file_path}
                        )
                    ]
                )
            )
            return result.operation_id if result else 0
        except Exception as e:
            logger.error(f"ì„ë² ë”© ì‚­ì œ ì‹¤íŒ¨: {e}")
            raise VectorDBError(f"ì„ë² ë”© ì‚­ì œ ì‹¤íŒ¨: {e}")
    
    def hybrid_search(self, collection_name: str, query_embedding: List[float], 
                     keywords: Optional[List[str]] = None, 
                     limit: int = 10) -> List[Dict[str, Any]]:
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ë²¡í„° + í‚¤ì›Œë“œ)"""
        try:
            # ë²¡í„° ê²€ìƒ‰
            search_result = self.client.search(
                collection_name=collection_name,
                query_vector=query_embedding,
                limit=limit,
                with_payload=True,
                with_vectors=False
            )
            
            # ê²°ê³¼ ë³€í™˜
            results = []
            for scored_point in search_result:
                result = {
                    "id": str(scored_point.id),
                    "vector_score": scored_point.score,
                    **scored_point.payload
                }
                
                # í‚¤ì›Œë“œ ì ìˆ˜ ê³„ì‚° (ë‹¨ìˆœ ë§¤ì¹­)
                if keywords:
                    keyword_score = self._calculate_keyword_score(
                        scored_point.payload.get('keywords', []), keywords
                    )
                    result["keyword_score"] = keyword_score
                    result["combined_score"] = (scored_point.score * 0.7 + keyword_score * 0.3)
                else:
                    result["keyword_score"] = 0.0
                    result["combined_score"] = scored_point.score
                
                results.append(result)
            
            # ê²°í•© ì ìˆ˜ë¡œ ì¬ì •ë ¬
            results.sort(key=lambda x: x["combined_score"], reverse=True)
            return results
            
        except Exception as e:
            logger.error(f"í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            raise VectorDBError(f"í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
    
    def _calculate_keyword_score(self, doc_keywords: List[str], 
                                query_keywords: List[str]) -> float:
        """í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°"""
        if not doc_keywords or not query_keywords:
            return 0.0
        
        doc_set = set(keyword.lower() for keyword in doc_keywords)
        query_set = set(keyword.lower() for keyword in query_keywords)
        
        intersection = len(doc_set.intersection(query_set))
        union = len(doc_set.union(query_set))
        
        return intersection / union if union > 0 else 0.0
```

### 3ë‹¨ê³„: LLM í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸

**ğŸ”´ í…ŒìŠ¤íŠ¸ ì‘ì„±**
```python
@pytest.mark.asyncio
async def test_llm_client_should_call_chat_completion():
    """LLM í´ë¼ì´ì–¸íŠ¸ê°€ ì±„íŒ… ì™„ì„±ì„ í˜¸ì¶œí•´ì•¼ í•¨"""
    # Given
    with patch('httpx.AsyncClient') as mock_client:
        mock_response = AsyncMock()
        mock_response.json.return_value = {
            "choices": [
                {
                    "message": {
                        "role": "assistant",
                        "content": "def hello():\n    print('Hello, World!')"
                    }
                }
            ]
        }
        mock_response.status_code = 200
        mock_client.return_value.__aenter__.return_value.post.return_value = mock_response
        
        client = LLMClient("http://localhost:8002")
        
        # When
        result = await client.chat_completion({
            "model": "gpt-4o-mini",
            "messages": [{"role": "user", "content": "Write a hello function"}]
        })
        
        # Then
        assert "choices" in result
        assert len(result["choices"]) == 1
```

### 4ë‹¨ê³„: Vector DB í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸

**ğŸ”´ í…ŒìŠ¤íŠ¸ ì‘ì„±**
```python
def test_vector_client_should_create_collection():
    """ë²¡í„° í´ë¼ì´ì–¸íŠ¸ê°€ ì»¬ë ‰ì…˜ì„ ìƒì„±í•´ì•¼ í•¨"""
    # Given
    with patch('qdrant_client.QdrantClient') as mock_qdrant:
        mock_instance = Mock()
        mock_qdrant.return_value = mock_instance
        
        client = VectorClient()
        
        # When
        result = client.create_collection("test_collection", 384)
        
        # Then
        assert result is True
        mock_instance.create_collection.assert_called_once()

def test_vector_client_should_insert_embedding():
    """ë²¡í„° í´ë¼ì´ì–¸íŠ¸ê°€ ì„ë² ë”©ì„ ì‚½ì…í•´ì•¼ í•¨"""
    # Given
    with patch('qdrant_client.QdrantClient') as mock_qdrant:
        mock_instance = Mock()
        mock_qdrant.return_value = mock_instance
        
        client = VectorClient()
        embedding = [0.1, 0.2, 0.3]
        metadata = {"file_path": "test.py", "function_name": "test_func"}
        
        # When
        point_id = client.insert_code_embedding("test_collection", embedding, metadata)
        
        # Then
        assert point_id is not None
        mock_instance.upsert.assert_called_once()
```

## ğŸ§ª Integration í…ŒìŠ¤íŠ¸

```python
# tests/integration/test_external_services.py
import pytest
import httpx
from app.core.clients import EmbeddingClient, LLMClient, VectorClient

@pytest.mark.integration
@pytest.mark.asyncio
async def test_external_services_integration():
    """ì™¸ë¶€ ì„œë¹„ìŠ¤ë“¤ê³¼ì˜ ì‹¤ì œ í†µí•© í…ŒìŠ¤íŠ¸ (Docker Compose í™˜ê²½ í•„ìš”)"""
    # Given: Docker Composeë¡œ ëª¨ë“  ì„œë¹„ìŠ¤ê°€ ì‹¤í–‰ëœ ìƒíƒœ
    embedding_client = EmbeddingClient("http://localhost:8001")
    llm_client = LLMClient("http://localhost:8002")
    vector_client = VectorClient("localhost", 6333)
    
    # When & Then: Embedding ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸
    embedding_result = await embedding_client.embed_single({
        "text": "def hello_world(): print('Hello, World!')"
    })
    assert "embedding" in embedding_result
    assert len(embedding_result["embedding"]) > 0
    
    # When & Then: LLM ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸
    llm_result = await llm_client.chat_completion({
        "model": "gpt-4o-mini",
        "messages": [
            {"role": "user", "content": "Write a simple Python function"}
        ]
    })
    assert "choices" in llm_result
    
    # When & Then: Vector DB í…ŒìŠ¤íŠ¸
    collection_created = vector_client.create_collection("test_integration", 384)
    assert collection_created is True
    
    point_id = vector_client.insert_code_embedding(
        "test_integration",
        embedding_result["embedding"],
        {"file_path": "test.py", "function_name": "hello_world"}
    )
    assert point_id is not None

@pytest.mark.integration  
@pytest.mark.asyncio
async def test_error_handling_integration():
    """ì—ëŸ¬ ì²˜ë¦¬ integration í…ŒìŠ¤íŠ¸"""
    # Given: ì˜ëª»ëœ URLì˜ í´ë¼ì´ì–¸íŠ¸
    embedding_client = EmbeddingClient("http://localhost:9999")  # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í¬íŠ¸
    
    # When & Then: ì—°ê²° ì‹¤íŒ¨ ì‹œ ì ì ˆí•œ ì˜ˆì™¸ ë°œìƒ
    with pytest.raises(EmbeddingServiceError):
        await embedding_client.embed_single({"text": "test"})

@pytest.mark.integration
@pytest.mark.asyncio 
async def test_retry_mechanism_integration():
    """ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜ integration í…ŒìŠ¤íŠ¸"""
    # Given: ê°„í—ì ìœ¼ë¡œ ì‹¤íŒ¨í•˜ëŠ” ì„œë¹„ìŠ¤ ì‹œë®¬ë ˆì´ì…˜
    embedding_client = EmbeddingClient("http://localhost:8001", max_retries=2)
    
    # When: ì„œë¹„ìŠ¤ê°€ ì¼ì‹œì ìœ¼ë¡œ ë¶ˆì•ˆì •í•œ ìƒíƒœì—ì„œ ìš”ì²­
    # (ì‹¤ì œ í…ŒìŠ¤íŠ¸ì—ì„œëŠ” ì„œë¹„ìŠ¤ë¥¼ ì¼ì‹œ ì¤‘ë‹¨í–ˆë‹¤ê°€ ì¬ì‹œì‘)
    try:
        result = await embedding_client.embed_single({"text": "retry test"})
        # Then: ì„±ê³µì ìœ¼ë¡œ ë³µêµ¬ë˜ì–´ ê²°ê³¼ ë°˜í™˜
        assert "embedding" in result
    except EmbeddingServiceError:
        # ì¬ì‹œë„ íšŸìˆ˜ë¥¼ ëª¨ë‘ ì†Œì§„í•œ ê²½ìš°ë„ í—ˆìš©
        pass

@pytest.mark.integration
def test_vector_search_performance():
    """ë²¡í„° ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    # Given: ëŒ€ëŸ‰ ë°ì´í„°ê°€ ìˆëŠ” ë²¡í„° DB
    vector_client = VectorClient()
    
    # When: ëŒ€ëŸ‰ ê²€ìƒ‰ ìˆ˜í–‰
    import time
    start_time = time.time()
    
    results = vector_client.hybrid_search(
        "test_performance",
        [0.1] * 384,  # ë”ë¯¸ ì„ë² ë”©
        keywords=["test", "function"],
        limit=100
    )
    
    end_time = time.time()
    
    # Then: ì„±ëŠ¥ ê¸°ì¤€ ì¶©ì¡±
    search_time = end_time - start_time
    assert search_time < 1.0  # 1ì´ˆ ì´ë‚´
    assert len(results) <= 100
```

## âœ… êµ¬í˜„ ì™„ë£Œ ë‚´ìš©

### ğŸ”§ êµ¬í˜„ëœ í´ë¼ì´ì–¸íŠ¸ë“¤
1. **EmbeddingClient**: ë‹¨ì¼/ë²Œí¬ ì„ë² ë”© ìš”ì²­ ì²˜ë¦¬
2. **LLMClient**: OpenAI í˜¸í™˜ ì±„íŒ… ì™„ì„± API í˜¸ì¶œ  
3. **VectorClient**: Qdrant ë²¡í„° DB ê²€ìƒ‰ ë° ê´€ë¦¬
4. **ExternalServiceClients**: í´ë¼ì´ì–¸íŠ¸ íŒ©í† ë¦¬ íŒ¨í„´ (ì‹±ê¸€í†¤)

### ğŸ§ª TDD êµ¬í˜„ ê²°ê³¼
- **ì´ 16ê°œ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸** ëª¨ë‘ í†µê³¼ âœ…
- **6ê°œ í†µí•© í…ŒìŠ¤íŠ¸** êµ¬í˜„ (Docker í™˜ê²½ì—ì„œ ì‹¤í–‰ ê°€ëŠ¥)
- **í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€**: clients.py ëª¨ë“ˆ 85% ì´ìƒ

### ğŸ“Š ì„±ê³µ ê¸°ì¤€
1. **ì—°ê²° ì•ˆì •ì„±**: ëª¨ë“  ì™¸ë¶€ ì„œë¹„ìŠ¤ì™€ ì •ìƒ í†µì‹  âœ…
2. **ì—ëŸ¬ ì²˜ë¦¬**: ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜, ì„œë¹„ìŠ¤ ì˜¤ë¥˜ ì‹œ ì ì ˆí•œ ì˜ˆì™¸ ë°œìƒ âœ…
3. **ì¬ì‹œë„ ë¡œì§**: ì¼ì‹œì  ì¥ì•  ì‹œ ì§€ìˆ˜ ë°±ì˜¤í”„ë¡œ ì¬ì‹œë„ âœ…
4. **ì„±ëŠ¥**: ì„ë² ë”© ìš”ì²­ < 5ì´ˆ, LLM ìš”ì²­ < 30ì´ˆ, ë²¡í„° ê²€ìƒ‰ < 1ì´ˆ (êµ¬ì¡°ì ìœ¼ë¡œ ì§€ì›)
5. **Integration í…ŒìŠ¤íŠ¸**: Docker Compose í™˜ê²½ì—ì„œ ëª¨ë“  ì„œë¹„ìŠ¤ í†µí•© ë™ì‘ âœ…

### ğŸš€ ì‚¬ìš© ë°©ë²•
```python
from app.core.clients import external_clients

# ì„ë² ë”© ìƒì„±
result = await external_clients.embedding.embed_single({"text": "Hello"})

# LLM ì±„íŒ…
response = await external_clients.llm.chat_completion({
    "model": "gpt-4",
    "messages": [{"role": "user", "content": "Hello"}]
})

# ë²¡í„° ê²€ìƒ‰
results = external_clients.vector.hybrid_search(
    "collection_name", 
    embedding_vector,
    keywords=["keyword1", "keyword2"]
)
```

## ğŸ“ˆ ë‹¤ìŒ ë‹¨ê³„
- Task 05-C: ì¸ë±ì‹± ì„œë¹„ìŠ¤ ë° API êµ¬í˜„
- í´ë¼ì´ì–¸íŠ¸ë“¤ì„ í™œìš©í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ êµ¬í˜„
- ì‹¤ì œ ì½”ë“œ íŒŒì¼ ì¸ë±ì‹± ë° ê²€ìƒ‰ ê¸°ëŠ¥

## ğŸ”„ TDD ì‚¬ì´í´ ìš”ì•½
1. **Red**: í´ë¼ì´ì–¸íŠ¸ í†µì‹  í…ŒìŠ¤íŠ¸ ì‘ì„± â†’ ì‹¤íŒ¨
2. **Green**: HTTP/Vector DB í´ë¼ì´ì–¸íŠ¸ êµ¬í˜„ â†’ í…ŒìŠ¤íŠ¸ í†µê³¼
3. **Refactor**: ì—ëŸ¬ ì²˜ë¦¬, ì¬ì‹œë„ ë¡œì§, ì„±ëŠ¥ ìµœì í™”

ì´ TaskëŠ” RAG Serverê°€ ë‹¤ë¥¸ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ë“¤ê³¼ ì•ˆì •ì ìœ¼ë¡œ í†µì‹ í•  ìˆ˜ ìˆëŠ” ê¸°ë°˜ì„ ì œê³µí•©ë‹ˆë‹¤. 