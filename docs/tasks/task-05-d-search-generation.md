# Task 05-D: ê²€ìƒ‰ ë° ì½”ë“œ ìƒì„± ì„œë¹„ìŠ¤ êµ¬í˜„

## ğŸ¯ ëª©í‘œ
í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê³¼ ì½”ë“œ ìƒì„± ê¸°ëŠ¥ì„ í†µí•©í•œ RAG ì„œë¹„ìŠ¤ë¥¼ TDD ë°©ì‹ìœ¼ë¡œ êµ¬í˜„í•©ë‹ˆë‹¤.

## ğŸ“‹ MVP ë²”ìœ„
- í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì„œë¹„ìŠ¤ (ë²¡í„° + í‚¤ì›Œë“œ)
- ì½”ë“œ ìƒì„± ì„œë¹„ìŠ¤ (RAG ê¸°ë°˜)
- ê²€ìƒ‰ ë° ìƒì„± REST API
- ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì½”ë“œ ìƒì„±

## ğŸ—ï¸ ê¸°ìˆ  ìŠ¤íƒ
- **ì›¹ í”„ë ˆì„ì›Œí¬**: FastAPI
- **RAG íŒŒì´í”„ë¼ì¸**: LangChain/ì»¤ìŠ¤í…€ êµ¬í˜„
- **í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§**: ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ í…œí”Œë¦¿
- **í…ŒìŠ¤íŠ¸**: pytest, httpx

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
rag-server/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â”œâ”€â”€ search/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ router.py        â† ê²€ìƒ‰ API
â”‚   â”‚   â”‚   â”œâ”€â”€ service.py       â† ê²€ìƒ‰ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
â”‚   â”‚   â”‚   â”œâ”€â”€ schema.py        â† ê²€ìƒ‰ ìŠ¤í‚¤ë§ˆ
â”‚   â”‚   â”‚   â””â”€â”€ retriever.py     â† í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸°
â”‚   â”‚   â””â”€â”€ generation/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ router.py        â† ìƒì„± API
â”‚   â”‚       â”œâ”€â”€ service.py       â† ìƒì„± ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
â”‚   â”‚       â”œâ”€â”€ schema.py        â† ìƒì„± ìŠ¤í‚¤ë§ˆ
â”‚   â”‚       â”œâ”€â”€ generator.py     â† ì½”ë“œ ìƒì„±ê¸°
â”‚   â”‚       â””â”€â”€ prompts.py       â† í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/
â”‚   â”‚   â””â”€â”€ features/
â”‚   â”‚       â”œâ”€â”€ search/
â”‚   â”‚       â””â”€â”€ generation/
â”‚   â””â”€â”€ integration/
â”‚       â”œâ”€â”€ test_search_api.py
â”‚       â””â”€â”€ test_generation_api.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ pytest.ini
```

## ğŸ§ª TDD êµ¬í˜„ ìˆœì„œ

### 1ë‹¨ê³„: ê²€ìƒ‰ ìŠ¤í‚¤ë§ˆ ë° ì„œë¹„ìŠ¤ (TDD)

**ìŠ¤í‚¤ë§ˆ ì •ì˜**
```python
# app/features/search/schema.py
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
from datetime import datetime

class SearchRequest(BaseModel):
    query: str = Field(..., description="ê²€ìƒ‰ ì¿¼ë¦¬")
    keywords: Optional[List[str]] = Field(default=None, description="í‚¤ì›Œë“œ í•„í„°")
    limit: int = Field(default=10, min=1, max=50, description="ê²°ê³¼ ê°œìˆ˜")
    vector_weight: float = Field(default=0.7, min=0.0, max=1.0, description="ë²¡í„° ê°€ì¤‘ì¹˜")
    keyword_weight: float = Field(default=0.3, min=0.0, max=1.0, description="í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜")

class SearchResult(BaseModel):
    id: str
    file_path: str
    function_name: str
    code_content: str
    code_type: str
    language: str
    line_start: int
    line_end: int
    keywords: List[str]
    vector_score: float
    keyword_score: float
    combined_score: float

class SearchResponse(BaseModel):
    query: str
    results: List[SearchResult]
    total_results: int
    search_time_ms: int
```

**ğŸ”´ í…ŒìŠ¤íŠ¸ ì‘ì„±**
```python
# tests/unit/features/search/test_service.py
import pytest
from unittest.mock import Mock, AsyncMock
from app.features.search.service import SearchService
from app.features.search.schema import SearchRequest

@pytest.fixture
def mock_embedding_client():
    client = Mock()
    client.embed_single = AsyncMock()
    return client

@pytest.fixture
def mock_vector_client():
    client = Mock()
    client.hybrid_search = Mock()
    return client

@pytest.mark.asyncio
async def test_search_service_should_perform_hybrid_search(
    mock_embedding_client, mock_vector_client
):
    """ê²€ìƒ‰ ì„œë¹„ìŠ¤ê°€ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•´ì•¼ í•¨"""
    # Given
    service = SearchService(mock_embedding_client, mock_vector_client)
    
    mock_embedding_client.embed_single.return_value = {
        "embedding": [0.1, 0.2, 0.3]
    }
    
    mock_vector_client.hybrid_search.return_value = [
        {
            "id": "test-id",
            "file_path": "test.py",
            "function_name": "test_func",
            "code_content": "def test_func(): pass",
            "code_type": "function",
            "language": "python",
            "line_start": 1,
            "line_end": 1,
            "keywords": ["test", "func"],
            "vector_score": 0.9,
            "keyword_score": 0.8,
            "combined_score": 0.85
        }
    ]
    
    request = SearchRequest(query="test function", keywords=["test"])
    
    # When
    result = await service.search_code(request)
    
    # Then
    assert result.total_results == 1
    assert result.results[0].function_name == "test_func"
    assert result.results[0].combined_score == 0.85
    mock_embedding_client.embed_single.assert_called_once()
    mock_vector_client.hybrid_search.assert_called_once()

@pytest.mark.asyncio
async def test_search_service_should_handle_empty_results(
    mock_embedding_client, mock_vector_client
):
    """ê²€ìƒ‰ ì„œë¹„ìŠ¤ê°€ ë¹ˆ ê²°ê³¼ë¥¼ ì²˜ë¦¬í•´ì•¼ í•¨"""
    # Given
    service = SearchService(mock_embedding_client, mock_vector_client)
    
    mock_embedding_client.embed_single.return_value = {
        "embedding": [0.1, 0.2, 0.3]
    }
    
    mock_vector_client.hybrid_search.return_value = []
    
    request = SearchRequest(query="nonexistent function")
    
    # When
    result = await service.search_code(request)
    
    # Then
    assert result.total_results == 0
    assert len(result.results) == 0
```

**ğŸŸ¢ ìµœì†Œ êµ¬í˜„**
```python
# app/features/search/service.py
import time
from typing import List
from .schema import SearchRequest, SearchResponse, SearchResult
from app.core.clients import EmbeddingClient, VectorClient
import logging

logger = logging.getLogger(__name__)

class SearchService:
    def __init__(self, embedding_client: EmbeddingClient, vector_client: VectorClient):
        self.embedding_client = embedding_client
        self.vector_client = vector_client
        self.collection_name = "code_chunks"
    
    async def search_code(self, request: SearchRequest) -> SearchResponse:
        """ì½”ë“œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰"""
        start_time = time.time()
        
        try:
            # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
            embedding_response = await self.embedding_client.embed_single({
                "text": request.query
            })
            query_embedding = embedding_response["embedding"]
            
            # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìˆ˜í–‰
            search_results = self.vector_client.hybrid_search(
                collection_name=self.collection_name,
                query_embedding=query_embedding,
                keywords=request.keywords,
                limit=request.limit
            )
            
            # ê²°ê³¼ ë³€í™˜
            results = []
            for result in search_results:
                search_result = SearchResult(
                    id=result["id"],
                    file_path=result["file_path"],
                    function_name=result["function_name"],
                    code_content=result["code_content"],
                    code_type=result["code_type"],
                    language=result["language"],
                    line_start=result["line_start"],
                    line_end=result["line_end"],
                    keywords=result["keywords"],
                    vector_score=result["vector_score"],
                    keyword_score=result["keyword_score"],
                    combined_score=result["combined_score"]
                )
                results.append(search_result)
            
            end_time = time.time()
            search_time_ms = int((end_time - start_time) * 1000)
            
            return SearchResponse(
                query=request.query,
                results=results,
                total_results=len(results),
                search_time_ms=search_time_ms
            )
            
        except Exception as e:
            logger.error(f"ì½”ë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            raise
```

### 2ë‹¨ê³„: ì½”ë“œ ìƒì„± ì„œë¹„ìŠ¤ (TDD)

**ìŠ¤í‚¤ë§ˆ ì •ì˜**
```python
# app/features/generation/schema.py
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any

class GenerationRequest(BaseModel):
    query: str = Field(..., description="ì½”ë“œ ìƒì„± ìš”ì²­")
    context_limit: int = Field(default=3, min=1, max=10, description="ì»¨í…ìŠ¤íŠ¸ ê°œìˆ˜")
    language: str = Field(default="python", description="ìƒì„±í•  ì½”ë“œ ì–¸ì–´")
    include_tests: bool = Field(default=False, description="í…ŒìŠ¤íŠ¸ ì½”ë“œ í¬í•¨ ì—¬ë¶€")

class CodeContext(BaseModel):
    function_name: str
    code_content: str
    file_path: str
    relevance_score: float

class GenerationResponse(BaseModel):
    query: str
    generated_code: str
    contexts_used: List[CodeContext]
    generation_time_ms: int
    model_used: str
```

**ğŸ”´ í…ŒìŠ¤íŠ¸ ì‘ì„±**
```python
# tests/unit/features/generation/test_service.py
import pytest
from unittest.mock import Mock, AsyncMock, patch
from app.features.generation.service import GenerationService
from app.features.generation.schema import GenerationRequest
from app.features.search.schema import SearchResult

@pytest.fixture
def mock_search_service():
    service = Mock()
    service.search_code = AsyncMock()
    return service

@pytest.fixture
def mock_llm_client():
    client = Mock()
    client.chat_completion = AsyncMock()
    return client

@pytest.mark.asyncio
async def test_generation_service_should_generate_code_with_context(
    mock_search_service, mock_llm_client
):
    """ìƒì„± ì„œë¹„ìŠ¤ê°€ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì½”ë“œë¥¼ ìƒì„±í•´ì•¼ í•¨"""
    # Given
    service = GenerationService(mock_search_service, mock_llm_client)
    
    # Mock ê²€ìƒ‰ ê²°ê³¼
    mock_search_results = [
        SearchResult(
            id="1", file_path="test.py", function_name="test_func",
            code_content="def test_func(): pass", code_type="function",
            language="python", line_start=1, line_end=1,
            keywords=["test"], vector_score=0.9,
            keyword_score=0.8, combined_score=0.85
        )
    ]
    
    mock_search_service.search_code.return_value.results = mock_search_results
    
    # Mock LLM ì‘ë‹µ
    mock_llm_client.chat_completion.return_value = {
        "choices": [
            {
                "message": {
                    "content": "def calculate_sum(a, b):\n    return a + b"
                }
            }
        ]
    }
    
    request = GenerationRequest(query="Create a function to calculate sum")
    
    # When
    result = await service.generate_code(request)
    
    # Then
    assert result.generated_code == "def calculate_sum(a, b):\n    return a + b"
    assert len(result.contexts_used) == 1
    assert result.contexts_used[0].function_name == "test_func"
    mock_search_service.search_code.assert_called_once()
    mock_llm_client.chat_completion.assert_called_once()
```

**ğŸŸ¢ ìµœì†Œ êµ¬í˜„**
```python
# app/features/generation/service.py
import time
from typing import List
from .schema import GenerationRequest, GenerationResponse, CodeContext
from .prompts import CodeGenerationPrompts
from app.features.search.service import SearchService
from app.features.search.schema import SearchRequest
from app.core.clients import LLMClient
import logging

logger = logging.getLogger(__name__)

class GenerationService:
    def __init__(self, search_service: SearchService, llm_client: LLMClient):
        self.search_service = search_service
        self.llm_client = llm_client
        self.prompts = CodeGenerationPrompts()
    
    async def generate_code(self, request: GenerationRequest) -> GenerationResponse:
        """ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì½”ë“œ ìƒì„±"""
        start_time = time.time()
        
        try:
            # ê´€ë ¨ ì½”ë“œ ê²€ìƒ‰
            search_request = SearchRequest(
                query=request.query,
                limit=request.context_limit
            )
            search_response = await self.search_service.search_code(search_request)
            
            # ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
            contexts = []
            for result in search_response.results:
                context = CodeContext(
                    function_name=result.function_name,
                    code_content=result.code_content,
                    file_path=result.file_path,
                    relevance_score=result.combined_score
                )
                contexts.append(context)
            
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            system_prompt = self.prompts.get_system_prompt(request.language)
            user_prompt = self.prompts.get_user_prompt(
                request.query, contexts, request.include_tests
            )
            
            # LLM í˜¸ì¶œ
            llm_response = await self.llm_client.chat_completion({
                "model": "gpt-4o-mini",
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                "temperature": 0.1,
                "max_tokens": 2000
            })
            
            generated_code = llm_response["choices"][0]["message"]["content"]
            
            end_time = time.time()
            generation_time_ms = int((end_time - start_time) * 1000)
            
            return GenerationResponse(
                query=request.query,
                generated_code=generated_code,
                contexts_used=contexts,
                generation_time_ms=generation_time_ms,
                model_used="gpt-4o-mini"
            )
            
        except Exception as e:
            logger.error(f"ì½”ë“œ ìƒì„± ì‹¤íŒ¨: {e}")
            raise
```

### 3ë‹¨ê³„: í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (TDD)

```python
# app/features/generation/prompts.py
from typing import List
from .schema import CodeContext

class CodeGenerationPrompts:
    def get_system_prompt(self, language: str = "python") -> str:
        """ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        return f"""ë‹¹ì‹ ì€ {language} ì½”ë“œ ìƒì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        
ì£¼ìš” ì›ì¹™:
1. ì œê³µëœ ê¸°ì¡´ ì½”ë“œ íŒ¨í„´ê³¼ ìŠ¤íƒ€ì¼ì„ ë”°ë¥´ì„¸ìš”
2. ê¹”ë”í•˜ê³  ì½ê¸° ì‰¬ìš´ ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”
3. ì ì ˆí•œ ë…ìŠ¤íŠ¸ë§ê³¼ ì£¼ì„ì„ í¬í•¨í•˜ì„¸ìš”
4. ì—ëŸ¬ ì²˜ë¦¬ë¥¼ ê³ ë ¤í•˜ì„¸ìš”
5. íƒ€ì… íŒíŠ¸ë¥¼ ì‚¬ìš©í•˜ì„¸ìš” (Python 3.6+)

ì½”ë“œë§Œ ë°˜í™˜í•˜ê³  ì¶”ê°€ ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”."""

    def get_user_prompt(self, query: str, contexts: List[CodeContext], 
                       include_tests: bool = False) -> str:
        """ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        prompt = f"ìš”ì²­: {query}\n\n"
        
        if contexts:
            prompt += "ì°¸ê³ í•  ê¸°ì¡´ ì½”ë“œ:\n\n"
            for i, context in enumerate(contexts, 1):
                prompt += f"ì˜ˆì‹œ {i} ({context.function_name}):\n"
                prompt += f"```python\n{context.code_content}\n```\n\n"
        
        prompt += f"ìœ„ ì˜ˆì‹œë“¤ì„ ì°¸ê³ í•˜ì—¬ '{query}'ì— ëŒ€í•œ ì½”ë“œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”."
        
        if include_tests:
            prompt += " í…ŒìŠ¤íŠ¸ ì½”ë“œë„ í•¨ê»˜ í¬í•¨í•´ì£¼ì„¸ìš”."
        
        return prompt
```

### 4ë‹¨ê³„: API ë¼ìš°í„° (TDD)

**ğŸ”´ í…ŒìŠ¤íŠ¸ ì‘ì„±**
```python
# tests/unit/features/search/test_router.py
import pytest
from unittest.mock import Mock, AsyncMock
from fastapi.testclient import TestClient
from app.main import app

def test_search_endpoint_should_return_results():
    """ê²€ìƒ‰ ì—”ë“œí¬ì¸íŠ¸ê°€ ê²°ê³¼ë¥¼ ë°˜í™˜í•´ì•¼ í•¨"""
    # Given
    from app.features.search.schema import SearchResponse, SearchResult
    mock_response = SearchResponse(
        query="test function",
        results=[
            SearchResult(
                id="1", file_path="test.py", function_name="test_func",
                code_content="def test_func(): pass", code_type="function",
                language="python", line_start=1, line_end=1,
                keywords=["test"], vector_score=0.9,
                keyword_score=0.8, combined_score=0.85
            )
        ],
        total_results=1,
        search_time_ms=100
    )
    
    # Mock dependency
    mock_service = Mock()
    mock_service.search_code = AsyncMock(return_value=mock_response)
    
    app.dependency_overrides[SearchService] = lambda: mock_service
    client = TestClient(app)
    
    # When
    response = client.post("/api/v1/search", json={
        "query": "test function",
        "limit": 10
    })
    
    # Then
    assert response.status_code == 200
    data = response.json()
    assert data["total_results"] == 1
    assert len(data["results"]) == 1
    assert data["results"][0]["function_name"] == "test_func"
```

**ğŸŸ¢ ìµœì†Œ êµ¬í˜„**
```python
# app/features/search/router.py
from fastapi import APIRouter, Depends, HTTPException, status
from .service import SearchService
from .schema import SearchRequest, SearchResponse
from app.core.dependencies import get_search_service
import logging

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/api/v1/search", tags=["search"])

@router.post("/", response_model=SearchResponse)
async def search_code(
    request: SearchRequest,
    service: SearchService = Depends(get_search_service)
) -> SearchResponse:
    """ì½”ë“œ ê²€ìƒ‰"""
    try:
        return await service.search_code(request)
    except Exception as e:
        logger.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

# app/features/generation/router.py
from fastapi import APIRouter, Depends, HTTPException, status
from .service import GenerationService
from .schema import GenerationRequest, GenerationResponse
from app.core.dependencies import get_generation_service
import logging

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/api/v1/generate", tags=["generation"])

@router.post("/", response_model=GenerationResponse)
async def generate_code(
    request: GenerationRequest,
    service: GenerationService = Depends(get_generation_service)
) -> GenerationResponse:
    """ì½”ë“œ ìƒì„±"""
    try:
        return await service.generate_code(request)
    except Exception as e:
        logger.error(f"ì½”ë“œ ìƒì„± ì˜¤ë¥˜: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ì½”ë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )
```

## ğŸ§ª Integration í…ŒìŠ¤íŠ¸

```python
# tests/integration/test_rag_workflow.py
import pytest
import tempfile
import os
from fastapi.testclient import TestClient
from app.main import app

@pytest.mark.integration
def test_full_rag_workflow():
    """ì „ì²´ RAG ì›Œí¬í”Œë¡œìš° integration í…ŒìŠ¤íŠ¸"""
    # Given: ì½”ë“œ íŒŒì¼ ì¸ë±ì‹±
    with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
        f.write('''
def fibonacci(n):
    """í”¼ë³´ë‚˜ì¹˜ ìˆ˜ì—´ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜"""
    if n <= 1:
        return n
    return fibonacci(n-1) + fibonacci(n-2)

def factorial(n):
    """íŒ©í† ë¦¬ì–¼ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜"""
    if n <= 1:
        return 1
    return n * factorial(n-1)
''')
        temp_file_path = f.name
    
    try:
        client = TestClient(app)
        
        # 1. íŒŒì¼ ì¸ë±ì‹±
        index_response = client.post("/api/v1/indexing/file", json={
            "file_path": temp_file_path,
            "force_update": True
        })
        assert index_response.status_code == 200
        
        # 2. ì½”ë“œ ê²€ìƒ‰
        search_response = client.post("/api/v1/search", json={
            "query": "recursive function",
            "limit": 5
        })
        assert search_response.status_code == 200
        search_data = search_response.json()
        assert search_data["total_results"] > 0
        
        # 3. ì½”ë“œ ìƒì„±
        generate_response = client.post("/api/v1/generate", json={
            "query": "Create a recursive function to calculate power",
            "context_limit": 2,
            "language": "python"
        })
        assert generate_response.status_code == 200
        generate_data = generate_response.json()
        assert "def" in generate_data["generated_code"]
        assert len(generate_data["contexts_used"]) > 0
        
    finally:
        os.unlink(temp_file_path)

@pytest.mark.integration
def test_search_performance():
    """ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    client = TestClient(app)
    
    # When: ê²€ìƒ‰ ìˆ˜í–‰
    response = client.post("/api/v1/search", json={
        "query": "function calculation",
        "limit": 20
    })
    
    # Then: ì„±ëŠ¥ ê¸°ì¤€ ì¶©ì¡±
    assert response.status_code == 200
    data = response.json()
    assert data["search_time_ms"] < 5000  # 5ì´ˆ ì´ë‚´

@pytest.mark.integration  
def test_generation_with_different_contexts():
    """ë‹¤ì–‘í•œ ì»¨í…ìŠ¤íŠ¸ë¡œ ì½”ë“œ ìƒì„± í…ŒìŠ¤íŠ¸"""
    client = TestClient(app)
    
    # When: ë‹¤ì–‘í•œ ìš”ì²­ìœ¼ë¡œ ì½”ë“œ ìƒì„±
    requests = [
        "Create a sorting algorithm",
        "Write a class for data processing",
        "Implement error handling for file operations"
    ]
    
    for query in requests:
        response = client.post("/api/v1/generate", json={
            "query": query,
            "context_limit": 3,
            "include_tests": True
        })
        
        # Then: ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë¨
        assert response.status_code == 200
        data = response.json()
        assert data["generated_code"]
        assert data["generation_time_ms"] < 60000  # 1ë¶„ ì´ë‚´
```

## ğŸ“Š ì„±ê³µ ê¸°ì¤€
1. **ê²€ìƒ‰ ì„±ëŠ¥**: ì¿¼ë¦¬ ë‹¹ 5ì´ˆ ì´ë‚´ ì‘ë‹µ
2. **ìƒì„± í’ˆì§ˆ**: ìƒì„±ëœ ì½”ë“œê°€ êµ¬ë¬¸ì ìœ¼ë¡œ ì˜¬ë°”ë¦„
3. **ì»¨í…ìŠ¤íŠ¸ í™œìš©**: ê´€ë ¨ ì½”ë“œ íŒ¨í„´ ë°˜ì˜ë„ 80% ì´ìƒ
4. **ì‘ë‹µ ì†ë„**: ì½”ë“œ ìƒì„± 60ì´ˆ ì´ë‚´
5. **ì •í™•ë„**: ì‚¬ìš©ì ì˜ë„ ë°˜ì˜ë„ 85% ì´ìƒ (ìˆ˜ë™ í‰ê°€)

## ğŸ“ˆ ë‹¤ìŒ ë‹¨ê³„
- Task 06: ì „ì²´ ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸ ë° ê²€ì¦
- ì„±ëŠ¥ ìµœì í™” ë° ëª¨ë‹ˆí„°ë§ êµ¬í˜„
- í”„ë¡œë•ì…˜ ë°°í¬ ì¤€ë¹„

## ğŸ”„ TDD ì‚¬ì´í´ ìš”ì•½
1. **Red**: ê²€ìƒ‰/ìƒì„± ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸ ì‘ì„± â†’ ì‹¤íŒ¨
2. **Green**: RAG íŒŒì´í”„ë¼ì¸ ë° API êµ¬í˜„ â†’ í…ŒìŠ¤íŠ¸ í†µê³¼  
3. **Refactor**: í”„ë¡¬í”„íŠ¸ ìµœì í™”, ì„±ëŠ¥ ê°œì„ , ì½”ë“œ ì •ë¦¬

ì´ TaskëŠ” RAG ì‹œìŠ¤í…œì˜ í•µì‹¬ ê¸°ëŠ¥ì¸ ê²€ìƒ‰ê³¼ ìƒì„±ì„ ì™„ì„±í•˜ì—¬ ì‚¬ìš©ìì—ê²Œ ê°€ì¹˜ë¥¼ ì œê³µí•˜ëŠ” ë§ˆì§€ë§‰ ë‹¨ê³„ì…ë‹ˆë‹¤. 