# ğŸ“‹ Task 18: í†µí•© í…ŒìŠ¤íŠ¸ ë° E2E í…ŒìŠ¤íŠ¸ êµ¬í˜„

---

## ğŸ¯ ëª©í‘œ ë° ë²”ìœ„

í•˜ì´ë¸Œë¦¬ë“œ RAG ì‹œìŠ¤í…œì˜ **ì „ì²´ ì›Œí¬í”Œë¡œìš° ê²€ì¦**ì„ ìœ„í•œ í†µí•© í…ŒìŠ¤íŠ¸ ë° E2E í…ŒìŠ¤íŠ¸ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.  
êµ¬í˜„ëœ ëª¨ë“  ì»´í¬ë„ŒíŠ¸ê°€ ì˜¬ë°”ë¥´ê²Œ ì—°ë™ë˜ê³  ê¸°ëŒ€í•œ ì„±ëŠ¥ì„ ë°œíœ˜í•˜ëŠ”ì§€ ê²€ì¦í•©ë‹ˆë‹¤.

### ğŸ“Š ê²€ì¦ ëŒ€ìƒ ì£¼ìš” Flow

1. **ì½”ë“œ ì¸ë±ì‹± Flow**: íŒŒì‹± â†’ ë¬¸ì„œ ìƒì„± â†’ ì¸ë±ìŠ¤ ì €ì¥
2. **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ Flow**: BM25 + Vector ê²€ìƒ‰ â†’ ê²°ê³¼ ë³‘í•©
3. **LLM ì²´ì¸ Flow**: ê²€ìƒ‰ â†’ í”„ë¡¬í”„íŠ¸ êµ¬ì„± â†’ LLM ì‘ë‹µ
4. **í†µí•© API Flow**: í´ë¼ì´ì–¸íŠ¸ ìš”ì²­ â†’ ìµœì¢… ì‘ë‹µ
5. **ì„±ëŠ¥ ë° ì •í™•ë„ ê²€ì¦**: ì‘ë‹µ ì‹œê°„, ê²€ìƒ‰ í’ˆì§ˆ, ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰

---

## ğŸ“ êµ¬í˜„í•  í…ŒìŠ¤íŠ¸ êµ¬ì¡°

```
tests/
â”œâ”€â”€ integration/                      # í†µí•© í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ test_indexing_flow.py        # ì¸ë±ì‹± í”Œë¡œìš° í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ test_hybrid_search_flow.py   # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í”Œë¡œìš° í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ test_llm_chain_flow.py       # LLM ì²´ì¸ í”Œë¡œìš° í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ test_full_pipeline.py        # ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
â”‚   â””â”€â”€ test_performance.py          # ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸
â”œâ”€â”€ e2e/                             # E2E í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ test_api_endpoints.py        # API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ test_user_scenarios.py       # ì‚¬ìš©ì ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ test_error_handling.py       # ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
â”‚   â””â”€â”€ test_concurrent_requests.py  # ë™ì‹œ ìš”ì²­ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
â”œâ”€â”€ fixtures/                        # í…ŒìŠ¤íŠ¸ ë°ì´í„°
â”‚   â”œâ”€â”€ sample_java_files/           # í…ŒìŠ¤íŠ¸ìš© Java íŒŒì¼ë“¤
â”‚   â”œâ”€â”€ expected_responses/          # ê¸°ëŒ€ ì‘ë‹µ ë°ì´í„°
â”‚   â””â”€â”€ performance_baseline.json   # ì„±ëŠ¥ ê¸°ì¤€ê°’
â””â”€â”€ conftest.py                      # ê³µí†µ fixture
```

---

## ğŸ”§ ì„¸ë¶€ êµ¬í˜„ ì‚¬í•­

### 1. í†µí•© í…ŒìŠ¤íŠ¸ êµ¬í˜„

#### 1.1 ì¸ë±ì‹± Flow í…ŒìŠ¤íŠ¸
```python
# tests/integration/test_indexing_flow.py
import pytest
from app.retriever.ast_parser import JavaASTParser
from app.retriever.document_builder import DocumentBuilder
from app.index.vector_index import CodeVectorIndex
from app.index.bm25_index import CodeBM25Index

class TestIndexingFlow:
    """ì½”ë“œ íŒŒì‹±ë¶€í„° ì¸ë±ìŠ¤ ì €ì¥ê¹Œì§€ ì „ì²´ í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""
    
    @pytest.fixture
    def sample_java_file(self):
        return "tests/fixtures/sample_java_files/Calculator.java"
    
    async def test_full_indexing_pipeline(self, sample_java_file):
        """Java íŒŒì¼ â†’ AST íŒŒì‹± â†’ Document ìƒì„± â†’ ì¸ë±ìŠ¤ ì €ì¥"""
        # Given
        parser = JavaASTParser()
        builder = DocumentBuilder()
        vector_index = CodeVectorIndex()
        bm25_index = CodeBM25Index()
        
        # When - íŒŒì‹± ë° Document ìƒì„±
        parsed_methods = parser.parse_java_file(sample_java_file)
        documents = builder.build_from_parsed_methods(parsed_methods)
        
        # Then - Document ê²€ì¦
        assert len(documents) > 0
        assert all(doc.metadata.get('file_path') for doc in documents)
        assert all(doc.metadata.get('method_name') for doc in documents)
        
        # When - ì¸ë±ìŠ¤ ì €ì¥
        vector_index.add_documents(documents)
        bm25_index.add_documents(documents)
        
        # Then - ì¸ë±ìŠ¤ ê²€ì¦
        assert vector_index.get_document_count() == len(documents)
        assert bm25_index.get_document_count() == len(documents)
    
    async def test_batch_indexing_performance(self):
        """ëŒ€ìš©ëŸ‰ íŒŒì¼ ë°°ì¹˜ ì¸ë±ì‹± ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        # Given
        java_files = [
            "tests/fixtures/sample_java_files/Calculator.java",
            "tests/fixtures/sample_java_files/StringUtils.java",
            "tests/fixtures/sample_java_files/DatabaseManager.java"
        ]
        
        # When
        start_time = time.time()
        total_documents = 0
        
        for file_path in java_files:
            documents = await self._index_single_file(file_path)
            total_documents += len(documents)
        
        end_time = time.time()
        
        # Then
        indexing_time = end_time - start_time
        assert indexing_time < 30.0  # 30ì´ˆ ì´ë‚´ ì™„ë£Œ
        assert total_documents > 0
        
        # ì„±ëŠ¥ ê¸°ì¤€ ê²€ì¦
        docs_per_second = total_documents / indexing_time
        assert docs_per_second > 10  # ì´ˆë‹¹ 10ê°œ ì´ìƒ ì²˜ë¦¬
```

#### 1.2 í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ Flow í…ŒìŠ¤íŠ¸
```python
# tests/integration/test_hybrid_search_flow.py
import pytest
from app.retriever.hybrid_retriever import CodeHybridRetriever
from app.index.vector_index import CodeVectorIndex
from app.index.bm25_index import CodeBM25Index

class TestHybridSearchFlow:
    """BM25 + Vector í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""
    
    @pytest.fixture
    async def indexed_system(self):
        """ì¸ë±ì‹±ëœ í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ ì¤€ë¹„"""
        vector_index = CodeVectorIndex()
        bm25_index = CodeBM25Index()
        
        # í…ŒìŠ¤íŠ¸ ë¬¸ì„œë“¤ ì¸ë±ì‹±
        await self._index_test_documents(vector_index, bm25_index)
        
        retriever = CodeHybridRetriever(
            vector_retriever=vector_index.as_retriever(),
            bm25_retriever=bm25_index.as_retriever()
        )
        
        return retriever
    
    async def test_hybrid_search_accuracy(self, indexed_system):
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì •í™•ë„ í…ŒìŠ¤íŠ¸"""
        # Given
        retriever = indexed_system
        test_queries = [
            "calculate sum of two numbers",
            "string validation method",
            "database connection setup"
        ]
        
        for query in test_queries:
            # When
            results = await retriever.retrieve(query)
            
            # Then
            assert len(results) > 0
            assert len(results) <= 10  # ìµœëŒ€ 10ê°œ ê²°ê³¼
            
            # ê´€ë ¨ì„± ì ìˆ˜ ê²€ì¦
            for result in results:
                assert result.score > 0.0
                assert result.node.metadata.get('method_name')
                assert result.node.text
            
            # ì ìˆ˜ ìˆœ ì •ë ¬ ê²€ì¦
            scores = [result.score for result in results]
            assert scores == sorted(scores, reverse=True)
    
    async def test_search_performance_benchmark(self, indexed_system):
        """ê²€ìƒ‰ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸"""
        # Given
        retriever = indexed_system
        queries = [
            "find method for sorting array",
            "validate email format",
            "parse JSON response"
        ]
        
        # When
        total_time = 0
        total_queries = 0
        
        for query in queries:
            start_time = time.time()
            results = await retriever.retrieve(query)
            end_time = time.time()
            
            query_time = end_time - start_time
            total_time += query_time
            total_queries += 1
            
            # ê°œë³„ ì¿¼ë¦¬ ì„±ëŠ¥ ê²€ì¦
            assert query_time < 2.0  # 2ì´ˆ ì´ë‚´ ì‘ë‹µ
            assert len(results) > 0
        
        # Then
        avg_response_time = total_time / total_queries
        assert avg_response_time < 1.0  # í‰ê·  1ì´ˆ ì´ë‚´
```

#### 1.3 LLM ì²´ì¸ Flow í…ŒìŠ¤íŠ¸
```python
# tests/integration/test_llm_chain_flow.py
import pytest
from app.llm.langchain_prompt import CodePromptBuilder
from app.llm.llm_chain import CodeLLMChain
from app.retriever.hybrid_retriever import CodeHybridRetriever

class TestLLMChainFlow:
    """ê²€ìƒ‰ â†’ í”„ë¡¬í”„íŠ¸ êµ¬ì„± â†’ LLM ì‘ë‹µ í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""
    
    @pytest.fixture
    def llm_chain_setup(self):
        """LLM ì²´ì¸ í…ŒìŠ¤íŠ¸ í™˜ê²½ ì¤€ë¹„"""
        prompt_builder = CodePromptBuilder()
        llm_chain = CodeLLMChain()
        
        return prompt_builder, llm_chain
    
    async def test_prompt_generation_flow(self, llm_chain_setup):
        """ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸"""
        # Given
        prompt_builder, _ = llm_chain_setup
        
        mock_search_results = [
            {
                "method_name": "calculateSum",
                "code": "public int calculateSum(int a, int b) { return a + b; }",
                "file_path": "Calculator.java"
            }
        ]
        
        query = "ë‘ ìˆ«ìë¥¼ ë”í•˜ëŠ” ë°©ë²•"
        
        # When
        prompt = prompt_builder.build_explanation_prompt(
            query=query,
            search_results=mock_search_results
        )
        
        # Then
        assert query in prompt
        assert "calculateSum" in prompt
        assert "Calculator.java" in prompt
        assert "public int calculateSum" in prompt
    
    async def test_llm_response_quality(self, llm_chain_setup):
        """LLM ì‘ë‹µ í’ˆì§ˆ í…ŒìŠ¤íŠ¸"""
        # Given
        prompt_builder, llm_chain = llm_chain_setup
        
        # Mock ê²€ìƒ‰ ê²°ê³¼
        search_results = [
            {
                "method_name": "validateEmail",
                "code": """
                public boolean validateEmail(String email) {
                    return email.contains("@") && email.contains(".");
                }
                """,
                "file_path": "ValidationUtils.java"
            }
        ]
        
        query = "ì´ë©”ì¼ ìœ íš¨ì„± ê²€ì‚¬í•˜ëŠ” ë°©ë²•"
        
        # When
        prompt = prompt_builder.build_explanation_prompt(query, search_results)
        response = await llm_chain.generate_response(prompt)
        
        # Then
        assert response
        assert len(response) > 50  # ì¶©ë¶„í•œ ê¸¸ì´ì˜ ì‘ë‹µ
        assert "email" in response.lower()
        assert "validation" in response.lower() or "ìœ íš¨ì„±" in response
        
        # ì‘ë‹µ êµ¬ì¡° ê²€ì¦
        assert not response.startswith("Error:")
        assert "validateEmail" in response
```

### 2. E2E í…ŒìŠ¤íŠ¸ êµ¬í˜„

#### 2.1 API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸
```python
# tests/e2e/test_api_endpoints.py
import pytest
from fastapi.testclient import TestClient
from app.main import app

class TestAPIEndpoints:
    """í†µí•© API ì—”ë“œí¬ì¸íŠ¸ E2E í…ŒìŠ¤íŠ¸"""
    
    @pytest.fixture
    def client(self):
        return TestClient(app)
    
    async def test_search_snippet_endpoint(self, client):
        """ì½”ë“œ ìŠ¤ë‹ˆí« ê²€ìƒ‰ API í…ŒìŠ¤íŠ¸"""
        # Given
        query = "calculate sum of two numbers"
        
        # When
        response = client.get(f"/api/v1/search-snippet?query={query}")
        
        # Then
        assert response.status_code == 200
        
        data = response.json()
        assert "results" in data
        assert isinstance(data["results"], list)
        assert len(data["results"]) > 0
        
        # ê²°ê³¼ êµ¬ì¡° ê²€ì¦
        result = data["results"][0]
        assert "method_name" in result
        assert "code" in result
        assert "file_path" in result
        assert "score" in result
    
    async def test_explain_code_endpoint(self, client):
        """ì½”ë“œ ì„¤ëª… ìƒì„± API í…ŒìŠ¤íŠ¸"""
        # Given
        request_data = {
            "query": "ë‘ ìˆ«ìë¥¼ ë”í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”",
            "max_results": 5
        }
        
        # When
        response = client.post("/api/v1/explain", json=request_data)
        
        # Then
        assert response.status_code == 200
        
        data = response.json()
        assert "explanation" in data
        assert "search_results" in data
        assert "metadata" in data
        
        # ì„¤ëª… ë‚´ìš© ê²€ì¦
        explanation = data["explanation"]
        assert len(explanation) > 100  # ì¶©ë¶„í•œ ì„¤ëª…
        assert "ë”í•˜ê¸°" in explanation or "sum" in explanation.lower()
    
    async def test_index_code_endpoint(self, client):
        """ì½”ë“œ ì¸ë±ì‹± API í…ŒìŠ¤íŠ¸"""
        # Given
        index_request = {
            "file_path": "tests/fixtures/sample_java_files/Calculator.java",
            "language": "java"
        }
        
        # When
        response = client.post("/api/v1/index", json=index_request)
        
        # Then
        assert response.status_code == 201
        
        data = response.json()
        assert "indexed_methods" in data
        assert "processing_time" in data
        assert data["indexed_methods"] > 0
```

#### 2.2 ì‚¬ìš©ì ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸
```python
# tests/e2e/test_user_scenarios.py
import pytest
from fastapi.testclient import TestClient
from app.main import app

class TestUserScenarios:
    """ì‹¤ì œ ì‚¬ìš©ì ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ E2E í…ŒìŠ¤íŠ¸"""
    
    @pytest.fixture
    def client(self):
        return TestClient(app)
    
    async def test_developer_workflow_scenario(self, client):
        """ê°œë°œì ì›Œí¬í”Œë¡œìš° ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸"""
        # ì‹œë‚˜ë¦¬ì˜¤: ìƒˆ í”„ë¡œì íŠ¸ íŒŒì¼ ì¸ë±ì‹± â†’ ì½”ë“œ ê²€ìƒ‰ â†’ ì„¤ëª… ìš”ì²­
        
        # Step 1: ì½”ë“œ íŒŒì¼ ì¸ë±ì‹±
        index_response = client.post("/api/v1/index", json={
            "file_path": "tests/fixtures/sample_java_files/Calculator.java",
            "language": "java"
        })
        assert index_response.status_code == 201
        
        # Step 2: ê´€ë ¨ ì½”ë“œ ê²€ìƒ‰
        search_response = client.get("/api/v1/search-snippet?query=addition method")
        assert search_response.status_code == 200
        
        search_data = search_response.json()
        assert len(search_data["results"]) > 0
        
        # Step 3: ì½”ë“œ ì„¤ëª… ìš”ì²­
        explain_response = client.post("/api/v1/explain", json={
            "query": "ë§ì…ˆ ë©”ì„œë“œì˜ ë™ì‘ ì›ë¦¬ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”"
        })
        assert explain_response.status_code == 200
        
        explain_data = explain_response.json()
        assert "explanation" in explain_data
        assert len(explain_data["explanation"]) > 50
    
    async def test_code_review_scenario(self, client):
        """ì½”ë“œ ë¦¬ë·° ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸"""
        # ì‹œë‚˜ë¦¬ì˜¤: ì½”ë“œ ê²€ìƒ‰ â†’ ìœ ì‚¬ ì½”ë“œ ë¹„êµ â†’ ê°œì„  ì œì•ˆ
        
        # Step 1: íŠ¹ì • ê¸°ëŠ¥ ì½”ë“œ ê²€ìƒ‰
        search_response = client.get("/api/v1/search-snippet?query=string validation")
        assert search_response.status_code == 200
        
        # Step 2: ì½”ë“œ ë¦¬ë·° ë° ê°œì„  ì œì•ˆ ìš”ì²­
        review_response = client.post("/api/v1/explain", json={
            "query": "ì´ ë¬¸ìì—´ ê²€ì¦ ì½”ë“œë¥¼ ê°œì„ í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì€?",
            "include_suggestions": True
        })
        assert review_response.status_code == 200
        
        review_data = review_response.json()
        assert "explanation" in review_data
        assert "suggestions" in review_data.get("metadata", {})
```

### 3. ì„±ëŠ¥ ë° ë¶€í•˜ í…ŒìŠ¤íŠ¸
```python
# tests/integration/test_performance.py
import pytest
import asyncio
import time
from concurrent.futures import ThreadPoolExecutor
from fastapi.testclient import TestClient
from app.main import app

class TestPerformance:
    """ì„±ëŠ¥ ë° ë¶€í•˜ í…ŒìŠ¤íŠ¸"""
    
    @pytest.fixture
    def client(self):
        return TestClient(app)
    
    async def test_concurrent_search_requests(self, client):
        """ë™ì‹œ ê²€ìƒ‰ ìš”ì²­ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        # Given
        queries = [
            "calculate sum",
            "validate email",
            "parse json",
            "sort array",
            "handle exception"
        ]
        
        # When
        start_time = time.time()
        
        with ThreadPoolExecutor(max_workers=10) as executor:
            futures = [
                executor.submit(
                    client.get, 
                    f"/api/v1/search-snippet?query={query}"
                )
                for query in queries * 4  # 20ê°œ ë™ì‹œ ìš”ì²­
            ]
            
            responses = [future.result() for future in futures]
        
        end_time = time.time()
        
        # Then
        total_time = end_time - start_time
        assert total_time < 10.0  # 10ì´ˆ ì´ë‚´ ì™„ë£Œ
        
        # ëª¨ë“  ìš”ì²­ ì„±ê³µ ê²€ì¦
        for response in responses:
            assert response.status_code == 200
    
    async def test_memory_usage_monitoring(self, client):
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ í…ŒìŠ¤íŠ¸"""
        import psutil
        import os
        
        # Given
        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        # When - ëŒ€ëŸ‰ ìš”ì²­ ì²˜ë¦¬
        for i in range(100):
            response = client.get(f"/api/v1/search-snippet?query=test query {i}")
            assert response.status_code == 200
        
        # Then
        final_memory = process.memory_info().rss / 1024 / 1024  # MB
        memory_increase = final_memory - initial_memory
        
        # ë©”ëª¨ë¦¬ ì¦ê°€ëŸ‰ ì œí•œ (100MB ì´ë‚´)
        assert memory_increase < 100
```

---

## âœ… ì™„ë£Œ ê¸°ì¤€

### 1. ê¸°ëŠ¥ ê²€ì¦ ì™„ë£Œ
- [ ] ëª¨ë“  ì£¼ìš” Flow í†µí•© í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] E2E í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ëª¨ë‘ ì„±ê³µ
- [ ] API ì—”ë“œí¬ì¸íŠ¸ ì •ìƒ ë™ì‘ í™•ì¸
- [ ] ì—ëŸ¬ ì²˜ë¦¬ ë¡œì§ ê²€ì¦

### 2. ì„±ëŠ¥ ê¸°ì¤€ ë‹¬ì„±
- [ ] ë‹¨ì¼ ê²€ìƒ‰ ìš”ì²­: 2ì´ˆ ì´ë‚´ ì‘ë‹µ
- [ ] í‰ê·  ê²€ìƒ‰ ì‘ë‹µ ì‹œê°„: 1ì´ˆ ì´ë‚´
- [ ] ë™ì‹œ ìš”ì²­ ì²˜ë¦¬: 10ê°œ ì´ìƒ ë™ì‹œ ì²˜ë¦¬
- [ ] ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 100MB ì´ë‚´ ì¦ê°€

### 3. í’ˆì§ˆ ê¸°ì¤€ ì¶©ì¡±
- [ ] í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€: ì „ì²´ 90% ì´ìƒ
- [ ] í†µí•© í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€: 100%
- [ ] ëª¨ë“  ì£¼ìš” ì‚¬ìš©ì ì‹œë‚˜ë¦¬ì˜¤ ì»¤ë²„
- [ ] ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ê¸°ì¤€ê°’ ë‹¬ì„±

### 4. ë¬¸ì„œí™” ì™„ë£Œ
- [ ] í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ê°€ì´ë“œ ì‘ì„±
- [ ] ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ë³´ê³ ì„œ
- [ ] í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ ì‹œ ë””ë²„ê¹… ê°€ì´ë“œ
- [ ] CI/CD íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ í†µí•©

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë°©ë²•

```bash
# ì „ì²´ í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest tests/integration/ -v

# E2E í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest tests/e2e/ -v

# ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest tests/integration/test_performance.py -v

# ì»¤ë²„ë¦¬ì§€ í¬í•¨ ì „ì²´ í…ŒìŠ¤íŠ¸
pytest tests/ --cov=app --cov-report=html --cov-report=term-missing

# íŠ¹ì • ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸
pytest tests/e2e/test_user_scenarios.py::TestUserScenarios::test_developer_workflow_scenario -v
```

---

## ğŸ“Š ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ê¸°ì¤€

| ë©”íŠ¸ë¦­ | ëª©í‘œê°’ | ì¸¡ì • ë°©ë²• |
|-------|-------|----------|
| ê²€ìƒ‰ ì‘ë‹µ ì‹œê°„ | < 2ì´ˆ | ë‹¨ì¼ ìš”ì²­ ì²˜ë¦¬ ì‹œê°„ |
| í‰ê·  ì‘ë‹µ ì‹œê°„ | < 1ì´ˆ | 100íšŒ ìš”ì²­ í‰ê·  |
| ë™ì‹œ ì²˜ë¦¬ ëŠ¥ë ¥ | 10+ ìš”ì²­ | ë™ì‹œ ìš”ì²­ ì²˜ë¦¬ ìˆ˜ |
| ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ | < 100MB ì¦ê°€ | ëŒ€ëŸ‰ ìš”ì²­ í›„ ë©”ëª¨ë¦¬ ì¦ê°€ëŸ‰ |
| ì¸ë±ì‹± ì²˜ë¦¬ ì†ë„ | > 10 docs/sec | ë¬¸ì„œ ì¸ë±ì‹± ì†ë„ |
| ê²€ìƒ‰ ì •í™•ë„ | > 85% | ê´€ë ¨ì„± ì ìˆ˜ ê¸°ë°˜ í‰ê°€ |

---

## ğŸ¯ ì˜ˆìƒ ê²°ê³¼

ì´ Taskë¥¼ ì™„ë£Œí•˜ë©´:

1. **ì „ì²´ ì‹œìŠ¤í…œ ì•ˆì •ì„±** ë³´ì¥
2. **ì„±ëŠ¥ ê¸°ì¤€ ì¤€ìˆ˜** í™•ì¸
3. **ì‚¬ìš©ì ì‹œë‚˜ë¦¬ì˜¤** ê²€ì¦ ì™„ë£Œ
4. **í”„ë¡œë•ì…˜ ë°°í¬** ì¤€ë¹„ ì™„ë£Œ
5. **ì§€ì†ì ì¸ í’ˆì§ˆ ê´€ë¦¬** ê¸°ë°˜ êµ¬ì¶•

í•˜ì´ë¸Œë¦¬ë“œ RAG ì‹œìŠ¤í…œì´ ì‹¤ì œ ìš´ì˜ í™˜ê²½ì—ì„œ ì•ˆì •ì ìœ¼ë¡œ ë™ì‘í•  ìˆ˜ ìˆëŠ” ì‹ ë¢°ì„±ì„ í™•ë³´í•˜ê²Œ ë©ë‹ˆë‹¤. 