# Task 03: Vector DB êµ¬ì„±

## ğŸ¯ ëª©í‘œ
Qdrantë¥¼ ì‚¬ìš©í•˜ì—¬ ì½”ë“œ ì„ë² ë”©ì„ ì €ì¥í•˜ê³  ê²€ìƒ‰í•  ìˆ˜ ìˆëŠ” ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ êµ¬ì„±í•˜ê³ , í‚¤ì›Œë“œ ì¸ë±ìŠ¤ì™€ í†µí•©í•˜ì—¬ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì„ ì§€ì›í•©ë‹ˆë‹¤.

## ğŸ“‹ MVP ë²”ìœ„
- Qdrant ì»¨í…Œì´ë„ˆ ì„¤ì • ë° êµ¬ì„±
- ì½”ë“œ ì„ë² ë”© ì €ì¥ ìŠ¤í‚¤ë§ˆ ì„¤ê³„
- ë²¡í„° ê²€ìƒ‰ ê¸°ëŠ¥ êµ¬í˜„
- í‚¤ì›Œë“œ ì¸ë±ìŠ¤ í†µí•© (ê°„ë‹¨í•œ ë©”íƒ€ë°ì´í„° í•„í„°ë§)
- ë°ì´í„° ë°±ì—… ë° ë³µì› ì„¤ì •

## ğŸ—ï¸ ê¸°ìˆ  ìŠ¤íƒ
- **ë²¡í„° DB**: Qdrant
- **ì»¨í…Œì´ë„ˆ**: Docker
- **í´ë¼ì´ì–¸íŠ¸**: qdrant-client (Python)
- **í‚¤ì›Œë“œ ê²€ìƒ‰**: ë©”íƒ€ë°ì´í„° ê¸°ë°˜ í•„í„°ë§
- **ë°±ì—…**: Qdrant ìŠ¤ëƒ…ìƒ· ê¸°ëŠ¥

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
vector-db/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ qdrant.yaml             â† Qdrant ì„¤ì • íŒŒì¼
â”‚   â””â”€â”€ collection_config.json  â† ì»¬ë ‰ì…˜ ì„¤ì •
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ init_collections.py     â† ì»¬ë ‰ì…˜ ì´ˆê¸°í™” ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ backup.py              â† ë°±ì—… ìŠ¤í¬ë¦½íŠ¸
â”‚   â””â”€â”€ restore.py             â† ë³µì› ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_vector_operations.py
â”‚   â”œâ”€â”€ test_keyword_search.py
â”‚   â””â”€â”€ conftest.py
â”œâ”€â”€ docker-compose.yml          â† Qdrant ì„œë¹„ìŠ¤ ì •ì˜
â””â”€â”€ README.md                   â† ì„¤ì • ë° ì‚¬ìš© ê°€ì´ë“œ
```

## ğŸ—ƒï¸ ë°ì´í„° ìŠ¤í‚¤ë§ˆ ì„¤ê³„

### ì½”ë“œ ë²¡í„° ì»¬ë ‰ì…˜ êµ¬ì¡°
```json
{
  "collection_name": "code_embeddings",
  "vector_config": {
    "size": 384,
    "distance": "Cosine"
  },
  "payload_schema": {
    "file_path": "str",      // íŒŒì¼ ê²½ë¡œ
    "function_name": "str",   // í•¨ìˆ˜/í´ë˜ìŠ¤ëª…
    "code_type": "str",      // "function", "class", "method"
    "language": "str",       // "python", "javascript", etc.
    "code_content": "str",   // ì‹¤ì œ ì½”ë“œ ë‚´ìš©
    "line_start": "int",     // ì‹œì‘ ë¼ì¸ ë²ˆí˜¸
    "line_end": "int",       // ì¢…ë£Œ ë¼ì¸ ë²ˆí˜¸
    "created_at": "str",     // ìƒì„± ì‹œê°„ (ISO 8601)
    "keywords": ["str"]      // í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
  }
}
```

## ğŸ³ Docker êµ¬ì„±

### docker-compose.yml
```yaml
version: '3.8'
services:
  vector-db:
    image: qdrant/qdrant:v1.7.0
    container_name: qdrant-server
    ports:
      - "6333:6333"
      - "6334:6334"  # gRPC í¬íŠ¸
    volumes:
      - ./data/qdrant:/qdrant/storage
      - ./config/qdrant.yaml:/qdrant/config/production.yaml
    environment:
      - QDRANT__SERVICE__HTTP_PORT=6333
      - QDRANT__SERVICE__GRPC_PORT=6334
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
```

### Qdrant ì„¤ì • íŒŒì¼
```yaml
# config/qdrant.yaml
service:
  max_request_size_mb: 32
  max_workers: 0
  enable_cors: true

storage:
  storage_path: ./storage
  snapshots_path: ./snapshots
  temp_path: ./temp

log_level: INFO

cluster:
  enabled: false

telemetry_disabled: true
```

## ğŸ”§ ì»¬ë ‰ì…˜ ì´ˆê¸°í™”

### ì»¬ë ‰ì…˜ ìƒì„± ìŠ¤í¬ë¦½íŠ¸
```python
# scripts/init_collections.py
import asyncio
import logging
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams, CollectionInfo
import json

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class VectorDBInitializer:
    def __init__(self, host: str = "localhost", port: int = 6333):
        self.client = QdrantClient(host=host, port=port)
        
    def create_code_embeddings_collection(self):
        """ì½”ë“œ ì„ë² ë”© ì»¬ë ‰ì…˜ ìƒì„±"""
        collection_name = "code_embeddings"
        
        try:
            # ê¸°ì¡´ ì»¬ë ‰ì…˜ í™•ì¸
            collections = self.client.get_collections()
            existing_names = [col.name for col in collections.collections]
            
            if collection_name in existing_names:
                logger.info(f"ì»¬ë ‰ì…˜ '{collection_name}'ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")
                return
            
            # ì»¬ë ‰ì…˜ ìƒì„±
            self.client.create_collection(
                collection_name=collection_name,
                vectors_config=VectorParams(
                    size=384,  # sentence-transformers/all-MiniLM-L6-v2 ì°¨ì›
                    distance=Distance.COSINE
                )
            )
            
            logger.info(f"ì»¬ë ‰ì…˜ '{collection_name}' ìƒì„± ì™„ë£Œ")
            
            # ì¸ë±ìŠ¤ ì„¤ì •
            self.client.create_payload_index(
                collection_name=collection_name,
                field_name="file_path",
                field_schema="keyword"
            )
            
            self.client.create_payload_index(
                collection_name=collection_name,
                field_name="language",
                field_schema="keyword"
            )
            
            self.client.create_payload_index(
                collection_name=collection_name,
                field_name="code_type",
                field_schema="keyword"
            )
            
            logger.info("í˜ì´ë¡œë“œ ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"ì»¬ë ‰ì…˜ ìƒì„± ì‹¤íŒ¨: {e}")
            raise
    
    def get_collection_info(self, collection_name: str = "code_embeddings"):
        """ì»¬ë ‰ì…˜ ì •ë³´ ì¡°íšŒ"""
        try:
            info = self.client.get_collection(collection_name)
            logger.info(f"ì»¬ë ‰ì…˜ ì •ë³´: {info}")
            return info
        except Exception as e:
            logger.error(f"ì»¬ë ‰ì…˜ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    initializer = VectorDBInitializer()
    
    # ì»¬ë ‰ì…˜ ìƒì„±
    initializer.create_code_embeddings_collection()
    
    # ì»¬ë ‰ì…˜ ì •ë³´ í™•ì¸
    initializer.get_collection_info()

if __name__ == "__main__":
    main()
```

## ğŸ” ë²¡í„° ê²€ìƒ‰ ê¸°ëŠ¥

### ë²¡í„° ì—°ì‚° í´ë˜ìŠ¤
```python
# scripts/vector_operations.py
from typing import List, Dict, Any, Optional, Union
from qdrant_client import QdrantClient
from qdrant_client.models import PointStruct, Filter, FieldCondition, Range
import uuid
from datetime import datetime

class VectorOperations:
    def __init__(self, host: str = "localhost", port: int = 6333):
        self.client = QdrantClient(host=host, port=port)
        self.collection_name = "code_embeddings"
    
    def insert_code_embedding(
        self,
        embedding: List[float],
        file_path: str,
        function_name: str,
        code_content: str,
        code_type: str = "function",
        language: str = "python",
        line_start: int = 1,
        line_end: int = 1,
        keywords: Optional[List[str]] = None
    ) -> str:
        """ì½”ë“œ ì„ë² ë”© ì‚½ì…"""
        point_id = str(uuid.uuid4())
        
        payload = {
            "file_path": file_path,
            "function_name": function_name,
            "code_content": code_content,
            "code_type": code_type,
            "language": language,
            "line_start": line_start,
            "line_end": line_end,
            "created_at": datetime.utcnow().isoformat(),
            "keywords": keywords or []
        }
        
        point = PointStruct(
            id=point_id,
            vector=embedding,
            payload=payload
        )
        
        self.client.upsert(
            collection_name=self.collection_name,
            points=[point]
        )
        
        return point_id
    
    def search_similar_code(
        self,
        query_embedding: List[float],
        limit: int = 10,
        score_threshold: float = 0.7,
        language_filter: Optional[str] = None,
        code_type_filter: Optional[str] = None,
        file_path_filter: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """ìœ ì‚¬í•œ ì½”ë“œ ê²€ìƒ‰"""
        
        # í•„í„° êµ¬ì„±
        filters = []
        if language_filter:
            filters.append(FieldCondition(
                key="language",
                match={"value": language_filter}
            ))
        
        if code_type_filter:
            filters.append(FieldCondition(
                key="code_type",
                match={"value": code_type_filter}
            ))
        
        if file_path_filter:
            filters.append(FieldCondition(
                key="file_path",
                match={"value": file_path_filter}
            ))
        
        search_filter = Filter(must=filters) if filters else None
        
        # ê²€ìƒ‰ ì‹¤í–‰
        search_results = self.client.search(
            collection_name=self.collection_name,
            query_vector=query_embedding,
            query_filter=search_filter,
            limit=limit,
            score_threshold=score_threshold,
            with_payload=True
        )
        
        # ê²°ê³¼ í¬ë§·íŒ…
        results = []
        for hit in search_results:
            result = {
                "id": hit.id,
                "score": hit.score,
                "file_path": hit.payload.get("file_path"),
                "function_name": hit.payload.get("function_name"),
                "code_content": hit.payload.get("code_content"),
                "code_type": hit.payload.get("code_type"),
                "language": hit.payload.get("language"),
                "line_start": hit.payload.get("line_start"),
                "line_end": hit.payload.get("line_end"),
                "keywords": hit.payload.get("keywords", [])
            }
            results.append(result)
        
        return results
    
    def keyword_search(
        self,
        keywords: List[str],
        language: Optional[str] = None,
        limit: int = 10
    ) -> List[Dict[str, Any]]:
        """í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰"""
        
        filters = []
        
        # í‚¤ì›Œë“œ í•„í„° (OR ì¡°ê±´)
        for keyword in keywords:
            filters.append(FieldCondition(
                key="keywords",
                match={"value": keyword}
            ))
        
        # ì–¸ì–´ í•„í„°
        must_filters = []
        if language:
            must_filters.append(FieldCondition(
                key="language",
                match={"value": language}
            ))
        
        search_filter = Filter(
            should=filters,  # í‚¤ì›Œë“œ ì¤‘ í•˜ë‚˜ë¼ë„ ë§¤ì¹˜
            must=must_filters  # ë°˜ë“œì‹œ ë§Œì¡±í•´ì•¼ í•˜ëŠ” ì¡°ê±´
        )
        
        # í‚¤ì›Œë“œ ê²€ìƒ‰ (ì„ë² ë”© ì—†ì´)
        search_results = self.client.scroll(
            collection_name=self.collection_name,
            scroll_filter=search_filter,
            limit=limit,
            with_payload=True
        )
        
        results = []
        for point in search_results[0]:  # scroll ê²°ê³¼ì˜ ì²« ë²ˆì§¸ ìš”ì†Œ
            result = {
                "id": point.id,
                "file_path": point.payload.get("file_path"),
                "function_name": point.payload.get("function_name"),
                "code_content": point.payload.get("code_content"),
                "code_type": point.payload.get("code_type"),
                "language": point.payload.get("language"),
                "keywords": point.payload.get("keywords", [])
            }
            results.append(result)
        
        return results
    
    def hybrid_search(
        self,
        query_embedding: List[float],
        keywords: List[str],
        limit: int = 10,
        vector_weight: float = 0.7,
        keyword_weight: float = 0.3
    ) -> List[Dict[str, Any]]:
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ë²¡í„° + í‚¤ì›Œë“œ)"""
        
        # ë²¡í„° ê²€ìƒ‰ ê²°ê³¼
        vector_results = self.search_similar_code(
            query_embedding=query_embedding,
            limit=limit * 2  # ë” ë§ì€ ê²°ê³¼ë¥¼ ê°€ì ¸ì™€ì„œ ì¬ë­í‚¹
        )
        
        # í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼
        keyword_results = self.keyword_search(
            keywords=keywords,
            limit=limit * 2
        )
        
        # ê²°ê³¼ ê²°í•© ë° ì ìˆ˜ ê³„ì‚°
        combined_results = {}
        
        # ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ì¶”ê°€
        for i, result in enumerate(vector_results):
            result_id = result["id"]
            vector_score = result["score"] * vector_weight
            combined_results[result_id] = {
                **result,
                "vector_score": result["score"],
                "keyword_score": 0.0,
                "combined_score": vector_score
            }
        
        # í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼ ì¶”ê°€/ì—…ë°ì´íŠ¸
        for i, result in enumerate(keyword_results):
            result_id = result["id"]
            keyword_score = (1.0 - i / len(keyword_results)) * keyword_weight
            
            if result_id in combined_results:
                combined_results[result_id]["keyword_score"] = keyword_score
                combined_results[result_id]["combined_score"] += keyword_score
            else:
                combined_results[result_id] = {
                    **result,
                    "vector_score": 0.0,
                    "keyword_score": keyword_score,
                    "combined_score": keyword_score
                }
        
        # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_results = sorted(
            combined_results.values(),
            key=lambda x: x["combined_score"],
            reverse=True
        )
        
        return sorted_results[:limit]
    
    def delete_by_file_path(self, file_path: str) -> int:
        """íŒŒì¼ ê²½ë¡œë¡œ ê´€ë ¨ ë²¡í„° ì‚­ì œ"""
        filter_condition = Filter(
            must=[FieldCondition(
                key="file_path",
                match={"value": file_path}
            )]
        )
        
        result = self.client.delete(
            collection_name=self.collection_name,
            points_selector=filter_condition
        )
        
        return result.operation_id
    
    def get_collection_stats(self) -> Dict[str, Any]:
        """ì»¬ë ‰ì…˜ í†µê³„ ì •ë³´"""
        info = self.client.get_collection(self.collection_name)
        return {
            "points_count": info.points_count,
            "segments_count": info.segments_count,
            "vector_size": info.config.params.vectors.size,
            "distance": info.config.params.vectors.distance
        }
```

## ğŸ§ª í…ŒìŠ¤íŠ¸ êµ¬ì„±

### ë²¡í„° ì—°ì‚° í…ŒìŠ¤íŠ¸
```python
# tests/test_vector_operations.py
import pytest
from scripts.vector_operations import VectorOperations
import numpy as np

@pytest.fixture
def vector_ops():
    return VectorOperations()

@pytest.fixture
def sample_embedding():
    # 384ì°¨ì› ëœë¤ ì„ë² ë”© ìƒì„±
    return np.random.rand(384).tolist()

def test_insert_code_embedding_should_return_point_id(vector_ops, sample_embedding):
    """ì½”ë“œ ì„ë² ë”© ì‚½ì… ì‹œ í¬ì¸íŠ¸ IDë¥¼ ë°˜í™˜í•´ì•¼ í•¨"""
    # Given
    file_path = "test/sample.py"
    function_name = "test_function"
    code_content = "def test_function():\n    pass"
    
    # When
    point_id = vector_ops.insert_code_embedding(
        embedding=sample_embedding,
        file_path=file_path,
        function_name=function_name,
        code_content=code_content,
        keywords=["test", "function"]
    )
    
    # Then
    assert point_id is not None
    assert isinstance(point_id, str)

def test_search_similar_code_should_return_results(vector_ops, sample_embedding):
    """ìœ ì‚¬í•œ ì½”ë“œ ê²€ìƒ‰ ì‹œ ê²°ê³¼ë¥¼ ë°˜í™˜í•´ì•¼ í•¨"""
    # Given
    # ë¨¼ì € ë°ì´í„° ì‚½ì…
    vector_ops.insert_code_embedding(
        embedding=sample_embedding,
        file_path="test/example.py",
        function_name="example_function",
        code_content="def example_function():\n    return True",
        keywords=["example", "function"]
    )
    
    # When
    results = vector_ops.search_similar_code(
        query_embedding=sample_embedding,
        limit=5
    )
    
    # Then
    assert len(results) > 0
    assert "score" in results[0]
    assert "file_path" in results[0]
    assert "function_name" in results[0]

def test_keyword_search_should_return_matching_results(vector_ops, sample_embedding):
    """í‚¤ì›Œë“œ ê²€ìƒ‰ ì‹œ ë§¤ì¹­ë˜ëŠ” ê²°ê³¼ë¥¼ ë°˜í™˜í•´ì•¼ í•¨"""
    # Given
    keywords = ["example", "test"]
    vector_ops.insert_code_embedding(
        embedding=sample_embedding,
        file_path="test/keyword_test.py",
        function_name="keyword_function",
        code_content="def keyword_function():\n    pass",
        keywords=keywords
    )
    
    # When
    results = vector_ops.keyword_search(keywords=["example"])
    
    # Then
    assert len(results) > 0
    first_result = results[0]
    assert "example" in first_result["keywords"]

def test_hybrid_search_should_combine_vector_and_keyword_results(vector_ops, sample_embedding):
    """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹œ ë²¡í„°ì™€ í‚¤ì›Œë“œ ê²°ê³¼ë¥¼ ê²°í•©í•´ì•¼ í•¨"""
    # Given
    vector_ops.insert_code_embedding(
        embedding=sample_embedding,
        file_path="test/hybrid_test.py",
        function_name="hybrid_function",
        code_content="def hybrid_function():\n    return 'hybrid'",
        keywords=["hybrid", "test"]
    )
    
    # When
    results = vector_ops.hybrid_search(
        query_embedding=sample_embedding,
        keywords=["hybrid"],
        limit=5
    )
    
    # Then
    assert len(results) > 0
    first_result = results[0]
    assert "combined_score" in first_result
    assert "vector_score" in first_result
    assert "keyword_score" in first_result
```

## ğŸ’¾ ë°±ì—… ë° ë³µì›

### ë°±ì—… ìŠ¤í¬ë¦½íŠ¸
```python
# scripts/backup.py
import os
import shutil
from datetime import datetime
from qdrant_client import QdrantClient

class VectorDBBackup:
    def __init__(self, host: str = "localhost", port: int = 6333):
        self.client = QdrantClient(host=host, port=port)
        self.backup_dir = "./backups"
        
    def create_backup(self, collection_name: str = "code_embeddings") -> str:
        """ì»¬ë ‰ì…˜ ë°±ì—… ìƒì„±"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_path = f"{self.backup_dir}/{collection_name}_{timestamp}"
        
        os.makedirs(backup_path, exist_ok=True)
        
        # ìŠ¤ëƒ…ìƒ· ìƒì„±
        snapshot_info = self.client.create_snapshot(collection_name)
        
        print(f"ë°±ì—… ì™„ë£Œ: {backup_path}")
        return backup_path

if __name__ == "__main__":
    backup = VectorDBBackup()
    backup.create_backup()
```

## âœ… ì„±ê³µ ê¸°ì¤€

### ê¸°ëŠ¥ì  ìš”êµ¬ì‚¬í•­
- [ ] Qdrant ì»¨í…Œì´ë„ˆ ì •ìƒ ì‹¤í–‰
- [ ] ì½”ë“œ ì„ë² ë”© ì»¬ë ‰ì…˜ ìƒì„± ë° ì„¤ì •
- [ ] ë²¡í„° ê²€ìƒ‰ ê¸°ëŠ¥ ë™ì‘
- [ ] í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ ê¸°ëŠ¥ ë™ì‘
- [ ] í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê¸°ëŠ¥ ë™ì‘
- [ ] ë°ì´í„° ë°±ì—… ë° ë³µì› ê¸°ëŠ¥

### ë¹„ê¸°ëŠ¥ì  ìš”êµ¬ì‚¬í•­
- [ ] ê²€ìƒ‰ ì‘ë‹µ ì‹œê°„ < 1ì´ˆ (10k ë²¡í„° ê¸°ì¤€)
- [ ] ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘ ì‹œ ë°ì´í„° ë³´ì¡´
- [ ] ì ì ˆí•œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (< 2GB)
- [ ] í—¬ìŠ¤ ì²´í¬ ì •ìƒ ë™ì‘

### ë°ì´í„° í’ˆì§ˆ
- [ ] ì ì ˆí•œ ë²¡í„° ì¸ë±ì‹± ì„±ëŠ¥
- [ ] ë©”íƒ€ë°ì´í„° í•„í„°ë§ ì •í™•ì„±
- [ ] ì ìˆ˜ ê³„ì‚°ì˜ ì¼ê´€ì„±

## ğŸš€ ì‹¤í–‰ ë°©ë²•

### Docker Composeë¡œ ì‹¤í–‰
```bash
# Qdrant ì„œë¹„ìŠ¤ ì‹œì‘
docker-compose up -d vector-db

# í—¬ìŠ¤ ì²´í¬
curl http://localhost:6333/health

# ì»¬ë ‰ì…˜ ì´ˆê¸°í™”
python scripts/init_collections.py
```

### ê°œë°œ í™˜ê²½ ì„¤ì •
```bash
# Python í´ë¼ì´ì–¸íŠ¸ ì„¤ì¹˜
pip install qdrant-client

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest tests/test_vector_operations.py -v
```

## ğŸ“š API ë¬¸ì„œ
- Qdrant Web UI: http://localhost:6333/dashboard
- API ë¬¸ì„œ: http://localhost:6333/docs

## ğŸ§ª Integration í…ŒìŠ¤íŠ¸ ë‹¨ê³„

### Vector DB í†µí•© í…ŒìŠ¤íŠ¸

**ëª©í‘œ**: Qdrant Vector DBì˜ ì‹¤ì œ í™˜ê²½ ë™ì‘ ë° ë°ì´í„° ì¼ê´€ì„± ê²€ì¦

```python
# tests/integration/test_vector_db_integration.py
import pytest
import httpx
import asyncio
import random
import numpy as np

@pytest.mark.asyncio
class TestVectorDBIntegration:
    """Vector DB í†µí•© í…ŒìŠ¤íŠ¸"""
    
    @pytest.fixture(autouse=True)
    async def setup(self):
        """Docker Compose í™˜ê²½ì—ì„œ Vector DB ì‹œì‘ í™•ì¸"""
        async with httpx.AsyncClient() as client:
            # ì„œë¹„ìŠ¤ ì¤€ë¹„ ëŒ€ê¸° (ìµœëŒ€ 60ì´ˆ)
            for _ in range(60):
                try:
                    response = await client.get("http://localhost:6333/health")
                    if response.status_code == 200:
                        break
                    await asyncio.sleep(1)
                except:
                    await asyncio.sleep(1)
            else:
                pytest.fail("Vector DB ì„œë¹„ìŠ¤ê°€ ì‹œì‘ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        # í…ŒìŠ¤íŠ¸ìš© ì»¬ë ‰ì…˜ ìƒì„±
        await self.create_test_collection()
    
    async def create_test_collection(self):
        """í…ŒìŠ¤íŠ¸ìš© ì»¬ë ‰ì…˜ ìƒì„±"""
        async with httpx.AsyncClient() as client:
            # ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ (ìˆë‹¤ë©´)
            await client.delete("http://localhost:6333/collections/test_collection")
            
            # ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±
            collection_config = {
                "vectors": {
                    "size": 384,  # sentence-transformers ì„ë² ë”© ì°¨ì›
                    "distance": "Cosine"
                }
            }
            response = await client.put(
                "http://localhost:6333/collections/test_collection",
                json=collection_config
            )
            assert response.status_code == 200
    
    async def test_collection_management(self):
        """ì»¬ë ‰ì…˜ ê´€ë¦¬ í…ŒìŠ¤íŠ¸"""
        async with httpx.AsyncClient() as client:
            # ì»¬ë ‰ì…˜ ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ
            response = await client.get("http://localhost:6333/collections")
            assert response.status_code == 200
            collections = response.json()
            
            collection_names = [c["name"] for c in collections["result"]["collections"]]
            assert "test_collection" in collection_names
            
            # ì»¬ë ‰ì…˜ ì •ë³´ ì¡°íšŒ
            response = await client.get("http://localhost:6333/collections/test_collection")
            assert response.status_code == 200
            collection_info = response.json()
            assert collection_info["result"]["config"]["params"]["vectors"]["size"] == 384
            
            print("âœ… ì»¬ë ‰ì…˜ ê´€ë¦¬ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    
    async def test_vector_crud_operations(self):
        """ë²¡í„° CRUD ì—°ì‚° í…ŒìŠ¤íŠ¸"""
        async with httpx.AsyncClient() as client:
            # ë²¡í„° ì¶”ê°€
            test_vectors = []
            for i in range(10):
                vector = {
                    "id": i,
                    "vector": [random.random() for _ in range(384)],
                    "payload": {
                        "text": f"í…ŒìŠ¤íŠ¸ ë¬¸ì„œ {i}",
                        "category": "test",
                        "index": i
                    }
                }
                test_vectors.append(vector)
            
            upsert_data = {"points": test_vectors}
            response = await client.put(
                "http://localhost:6333/collections/test_collection/points",
                json=upsert_data
            )
            assert response.status_code == 200
            
            # ë²¡í„° ì¡°íšŒ
            response = await client.get(
                "http://localhost:6333/collections/test_collection/points/5"
            )
            assert response.status_code == 200
            point = response.json()["result"]
            assert point["payload"]["text"] == "í…ŒìŠ¤íŠ¸ ë¬¸ì„œ 5"
            
            # ë²¡í„° ì—…ë°ì´íŠ¸
            update_data = {
                "points": [{
                    "id": 5,
                    "payload": {"text": "ì—…ë°ì´íŠ¸ëœ ë¬¸ì„œ 5", "updated": True}
                }]
            }
            response = await client.put(
                "http://localhost:6333/collections/test_collection/points",
                json=update_data
            )
            assert response.status_code == 200
            
            # ì—…ë°ì´íŠ¸ í™•ì¸
            response = await client.get(
                "http://localhost:6333/collections/test_collection/points/5"
            )
            point = response.json()["result"]
            assert point["payload"]["text"] == "ì—…ë°ì´íŠ¸ëœ ë¬¸ì„œ 5"
            assert point["payload"]["updated"] is True
            
            # ë²¡í„° ì‚­ì œ
            delete_data = {"points": [0, 1, 2]}
            response = await client.post(
                "http://localhost:6333/collections/test_collection/points/delete",
                json=delete_data
            )
            assert response.status_code == 200
            
            print("âœ… ë²¡í„° CRUD ì—°ì‚° í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    
    async def test_vector_search_performance(self):
        """ë²¡í„° ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        async with httpx.AsyncClient() as client:
            # ëŒ€ëŸ‰ ë²¡í„° ë°ì´í„° ì¶”ê°€
            batch_size = 100
            test_vectors = []
            for i in range(batch_size):
                vector = {
                    "id": f"perf_{i}",
                    "vector": [random.random() for _ in range(384)],
                    "payload": {
                        "text": f"ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ë¬¸ì„œ {i}",
                        "batch": "performance"
                    }
                }
                test_vectors.append(vector)
            
            upsert_data = {"points": test_vectors}
            response = await client.put(
                "http://localhost:6333/collections/test_collection/points",
                json=upsert_data
            )
            assert response.status_code == 200
            
            # ê²€ìƒ‰ ì„±ëŠ¥ ì¸¡ì •
            search_vector = [random.random() for _ in range(384)]
            search_times = []
            
            for _ in range(5):  # 5íšŒ ì¸¡ì •
                start_time = asyncio.get_event_loop().time()
                
                search_data = {
                    "vector": search_vector,
                    "limit": 10,
                    "with_payload": True
                }
                
                response = await client.post(
                    "http://localhost:6333/collections/test_collection/points/search",
                    json=search_data
                )
                
                end_time = asyncio.get_event_loop().time()
                search_time = end_time - start_time
                search_times.append(search_time)
                
                assert response.status_code == 200
                results = response.json()["result"]
                assert len(results) <= 10
            
            avg_search_time = sum(search_times) / len(search_times)
            assert avg_search_time < 1.0  # í‰ê·  ê²€ìƒ‰ ì‹œê°„ 1ì´ˆ ì´ë‚´
            
            print(f"âœ… ë²¡í„° ê²€ìƒ‰ ì„±ëŠ¥: í‰ê·  {avg_search_time:.3f}ì´ˆ")
            print(f"ê°œë³„ ì¸¡ì •: {[f'{t:.3f}s' for t in search_times]}")
    
    async def test_hybrid_search(self):
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ (ë²¡í„° + í•„í„°)"""
        async with httpx.AsyncClient() as client:
            # ì¹´í…Œê³ ë¦¬ë³„ ë²¡í„° ì¶”ê°€
            categories = ["python", "javascript", "java"]
            for category in categories:
                test_vectors = []
                for i in range(20):
                    vector = {
                        "id": f"{category}_{i}",
                        "vector": [random.random() for _ in range(384)],
                        "payload": {
                            "text": f"{category} ì½”ë“œ ì˜ˆì œ {i}",
                            "language": category,
                            "complexity": random.choice(["low", "medium", "high"])
                        }
                    }
                    test_vectors.append(vector)
                
                upsert_data = {"points": test_vectors}
                response = await client.put(
                    "http://localhost:6333/collections/test_collection/points",
                    json=upsert_data
                )
                assert response.status_code == 200
            
            # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (python + medium complexity)
            search_vector = [random.random() for _ in range(384)]
            search_data = {
                "vector": search_vector,
                "limit": 10,
                "filter": {
                    "must": [
                        {"key": "language", "match": {"value": "python"}},
                        {"key": "complexity", "match": {"value": "medium"}}
                    ]
                },
                "with_payload": True
            }
            
            response = await client.post(
                "http://localhost:6333/collections/test_collection/points/search",
                json=search_data
            )
            
            assert response.status_code == 200
            results = response.json()["result"]
            
            # ê²°ê³¼ ê²€ì¦
            for result in results:
                payload = result["payload"]
                assert payload["language"] == "python"
                assert payload["complexity"] == "medium"
            
            print(f"âœ… í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
    
    async def test_concurrent_operations(self):
        """ë™ì‹œ ì—°ì‚° ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        async with httpx.AsyncClient() as client:
            # ë™ì‹œ ê²€ìƒ‰ ìš”ì²­
            search_vector = [random.random() for _ in range(384)]
            search_data = {
                "vector": search_vector,
                "limit": 5
            }
            
            tasks = []
            for i in range(20):  # 20ê°œ ë™ì‹œ ê²€ìƒ‰
                task = client.post(
                    "http://localhost:6333/collections/test_collection/points/search",
                    json=search_data
                )
                tasks.append(task)
            
            responses = await asyncio.gather(*tasks, return_exceptions=True)
            
            success_count = 0
            for response in responses:
                if not isinstance(response, Exception) and response.status_code == 200:
                    success_count += 1
            
            assert success_count >= 18, f"ë™ì‹œ ê²€ìƒ‰ ì‹¤íŒ¨: {success_count}/20"
            print(f"âœ… ë™ì‹œ ê²€ìƒ‰ ì„±ê³µ: {success_count}/20")
    
    async def teardown(self):
        """í…ŒìŠ¤íŠ¸ ì •ë¦¬"""
        async with httpx.AsyncClient() as client:
            # í…ŒìŠ¤íŠ¸ ì»¬ë ‰ì…˜ ì‚­ì œ
            await client.delete("http://localhost:6333/collections/test_collection")
```

**ì‹¤í–‰ ë°©ë²•**:
```bash
# Docker Compose í™˜ê²½ ì‹œì‘
docker-compose up -d vector-db

# Vector DB ì¤€ë¹„ ëŒ€ê¸°
sleep 30

# Integration í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest tests/integration/test_vector_db_integration.py -v

# ì„±ê³µ ê¸°ì¤€
# - ì»¬ë ‰ì…˜ ê´€ë¦¬ ì •ìƒ ë™ì‘
# - ë²¡í„° CRUD ì—°ì‚° ì„±ê³µ
# - ê²€ìƒ‰ ì„±ëŠ¥ < 1ì´ˆ
# - í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì •ìƒ ë™ì‘
# - ë™ì‹œ ì—°ì‚° ì„±ê³µë¥  > 90%
```

## ğŸ”„ ë‹¤ìŒ ë‹¨ê³„
Task 04: RAG Server êµ¬í˜„ 