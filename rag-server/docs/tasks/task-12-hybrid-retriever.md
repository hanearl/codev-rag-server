# Task 12: Hybrid Retriever êµ¬í˜„

## ğŸ“‹ ì‘ì—… ê°œìš”
Vector Indexì™€ BM25 Indexë¥¼ ê²°í•©í•˜ì—¬ ì˜ë¯¸ì  ê²€ìƒ‰ê³¼ í‚¤ì›Œë“œ ê²€ìƒ‰ì˜ ì¥ì ì„ ëª¨ë‘ í™œìš©í•˜ëŠ” Hybrid Retrieverë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤. RRF(Reciprocal Rank Fusion) ë° ê°€ì¤‘ì¹˜ ê¸°ë°˜ ê²°í•© ì „ëµì„ ì§€ì›í•©ë‹ˆë‹¤.

## ğŸ¯ ì‘ì—… ëª©í‘œ
- LlamaIndex BaseRetrieverë¥¼ ìƒì†í•œ Hybrid Retriever êµ¬í˜„
- Vector ê²€ìƒ‰ê³¼ BM25 ê²€ìƒ‰ ê²°ê³¼ì˜ íš¨ê³¼ì ì¸ ê²°í•©
- RRF ë° ê°€ì¤‘ì¹˜ ê¸°ë°˜ ìŠ¤ì½”ì–´ë§ ì „ëµ êµ¬í˜„
- ê¸°ì¡´ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ë¡œì§ê³¼ì˜ í˜¸í™˜ì„± ë³´ì¥

## ğŸ”— ì˜ì¡´ì„±
- **ì„ í–‰ Task**: Task 10 (Vector Index), Task 11 (BM25 Index)
- **í™œìš©í•  ê¸°ì¡´ ì½”ë“œ**: `app/features/search/retriever.py`, `app/features/search/scorer.py`

## ğŸ”§ êµ¬í˜„ ì‚¬í•­

### 1. Hybrid Retriever í•µì‹¬ êµ¬í˜„

```python
# app/retriever/hybrid_retriever.py
from typing import List, Dict, Any, Optional, Union
from llama_index.core.retrievers import BaseRetriever
from llama_index.core.schema import NodeWithScore, QueryBundle, TextNode
from llama_index.core import Document
import asyncio
import time
import logging
from .base_retriever import BaseRetriever as BaseRetrieverInterface, RetrievalResult
from app.index.vector_index import CodeVectorIndex
from app.index.bm25_index import CodeBM25Index

logger = logging.getLogger(__name__)

class HybridScoringStrategy:
    """í•˜ì´ë¸Œë¦¬ë“œ ìŠ¤ì½”ì–´ë§ ì „ëµ"""
    
    @staticmethod
    def weighted_average(
        vector_results: List[Dict[str, Any]], 
        bm25_results: List[Dict[str, Any]],
        vector_weight: float = 0.7,
        bm25_weight: float = 0.3
    ) -> List[Dict[str, Any]]:
        """ê°€ì¤‘í‰ê·  ê¸°ë°˜ ìŠ¤ì½”ì–´ë§"""
        # ê²°ê³¼ë¥¼ IDë³„ë¡œ ê·¸ë£¹í™”
        results_map = {}
        
        # Vector ê²°ê³¼ ì²˜ë¦¬
        for result in vector_results:
            doc_id = result['id']
            results_map[doc_id] = {
                **result,
                'vector_score': result['score'],
                'bm25_score': 0.0,
                'combined_score': result['score'] * vector_weight,
                'sources': ['vector']
            }
        
        # BM25 ê²°ê³¼ ì²˜ë¦¬
        for result in bm25_results:
            doc_id = result['id']
            if doc_id in results_map:
                # ê¸°ì¡´ ê²°ê³¼ì— BM25 ì ìˆ˜ ì¶”ê°€
                results_map[doc_id]['bm25_score'] = result['score']
                results_map[doc_id]['combined_score'] += result['score'] * bm25_weight
                results_map[doc_id]['sources'].append('bm25')
            else:
                # ìƒˆë¡œìš´ BM25 ê²°ê³¼
                results_map[doc_id] = {
                    **result,
                    'vector_score': 0.0,
                    'bm25_score': result['score'],
                    'combined_score': result['score'] * bm25_weight,
                    'sources': ['bm25']
                }
        
        # ì ìˆ˜ë³„ ì •ë ¬
        combined_results = list(results_map.values())
        combined_results.sort(key=lambda x: x['combined_score'], reverse=True)
        
        return combined_results
    
    @staticmethod
    def reciprocal_rank_fusion(
        vector_results: List[Dict[str, Any]], 
        bm25_results: List[Dict[str, Any]],
        k: int = 60
    ) -> List[Dict[str, Any]]:
        """RRF (Reciprocal Rank Fusion) ê¸°ë°˜ ìŠ¤ì½”ì–´ë§"""
        results_map = {}
        
        # Vector ê²°ê³¼ì˜ ìˆœìœ„ ê¸°ë°˜ ì ìˆ˜
        for rank, result in enumerate(vector_results):
            doc_id = result['id']
            rrf_score = 1.0 / (k + rank + 1)
            
            results_map[doc_id] = {
                **result,
                'vector_score': result['score'],
                'vector_rank': rank + 1,
                'bm25_score': 0.0,
                'bm25_rank': None,
                'rrf_score': rrf_score,
                'sources': ['vector']
            }
        
        # BM25 ê²°ê³¼ì˜ ìˆœìœ„ ê¸°ë°˜ ì ìˆ˜ ì¶”ê°€
        for rank, result in enumerate(bm25_results):
            doc_id = result['id']
            rrf_score = 1.0 / (k + rank + 1)
            
            if doc_id in results_map:
                # ê¸°ì¡´ ê²°ê³¼ì— BM25 RRF ì ìˆ˜ ì¶”ê°€
                results_map[doc_id]['bm25_score'] = result['score']
                results_map[doc_id]['bm25_rank'] = rank + 1
                results_map[doc_id]['rrf_score'] += rrf_score
                results_map[doc_id]['sources'].append('bm25')
            else:
                # ìƒˆë¡œìš´ BM25 ê²°ê³¼
                results_map[doc_id] = {
                    **result,
                    'vector_score': 0.0,
                    'vector_rank': None,
                    'bm25_score': result['score'],
                    'bm25_rank': rank + 1,
                    'rrf_score': rrf_score,
                    'sources': ['bm25']
                }
        
        # RRF ì ìˆ˜ë¡œ ì •ë ¬
        combined_results = list(results_map.values())
        combined_results.sort(key=lambda x: x['rrf_score'], reverse=True)
        
        # combined_scoreë¥¼ rrf_scoreë¡œ ì„¤ì •
        for result in combined_results:
            result['combined_score'] = result['rrf_score']
        
        return combined_results

class CodeHybridRetriever(BaseRetriever):
    """ì½”ë“œ í•˜ì´ë¸Œë¦¬ë“œ ë¦¬íŠ¸ë¦¬ë²„"""
    
    def __init__(
        self,
        vector_index: CodeVectorIndex,
        bm25_index: CodeBM25Index,
        vector_weight: float = 0.7,
        bm25_weight: float = 0.3,
        use_rrf: bool = True,
        rrf_k: int = 60,
        max_results: int = 50,
        enable_filtering: bool = True
    ):
        super().__init__()
        self.vector_index = vector_index
        self.bm25_index = bm25_index
        self.vector_weight = vector_weight
        self.bm25_weight = bm25_weight
        self.use_rrf = use_rrf
        self.rrf_k = rrf_k
        self.max_results = max_results
        self.enable_filtering = enable_filtering
        self.scoring_strategy = HybridScoringStrategy()
    
    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤í–‰"""
        query = query_bundle.query_str
        
        # ë³‘ë ¬ë¡œ Vectorì™€ BM25 ê²€ìƒ‰ ì‹¤í–‰
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        try:
            vector_results, bm25_results = loop.run_until_complete(
                self._parallel_search(query)
            )
        finally:
            loop.close()
        
        # ê²°ê³¼ ê²°í•©
        if self.use_rrf:
            combined_results = self.scoring_strategy.reciprocal_rank_fusion(
                vector_results, bm25_results, self.rrf_k
            )
        else:
            combined_results = self.scoring_strategy.weighted_average(
                vector_results, bm25_results, 
                self.vector_weight, self.bm25_weight
            )
        
        # NodeWithScore ê°ì²´ë¡œ ë³€í™˜
        nodes_with_scores = []
        for result in combined_results[:self.max_results]:
            node = TextNode(
                text=result['content'],
                metadata=result['metadata'],
                id_=result['id']
            )
            
            node_with_score = NodeWithScore(
                node=node,
                score=result['combined_score']
            )
            nodes_with_scores.append(node_with_score)
        
        return nodes_with_scores
    
    async def _parallel_search(self, query: str) -> tuple:
        """ë³‘ë ¬ ê²€ìƒ‰ ì‹¤í–‰"""
        # Vectorì™€ BM25 ê²€ìƒ‰ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰
        vector_task = self.vector_index.search_with_scores(
            query, limit=self.max_results
        )
        bm25_task = self.bm25_index.search_with_scores(
            query, limit=self.max_results
        )
        
        vector_results, bm25_results = await asyncio.gather(
            vector_task, bm25_task, return_exceptions=True
        )
        
        # ì˜ˆì™¸ ì²˜ë¦¬
        if isinstance(vector_results, Exception):
            logger.error(f"Vector ê²€ìƒ‰ ì‹¤íŒ¨: {vector_results}")
            vector_results = []
        
        if isinstance(bm25_results, Exception):
            logger.error(f"BM25 ê²€ìƒ‰ ì‹¤íŒ¨: {bm25_results}")
            bm25_results = []
        
        return vector_results, bm25_results

class HybridRetrievalService(BaseRetrieverInterface):
    """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì„œë¹„ìŠ¤"""
    
    def __init__(
        self,
        vector_index: CodeVectorIndex,
        bm25_index: CodeBM25Index,
        config: Optional[Dict[str, Any]] = None
    ):
        self.vector_index = vector_index
        self.bm25_index = bm25_index
        self.config = config or {}
        self.hybrid_retriever = None
        self._initialized = False
    
    async def setup(self) -> None:
        """ë¦¬íŠ¸ë¦¬ë²„ ì´ˆê¸°í™”"""
        if not self._initialized:
            # ì¸ë±ìŠ¤ë“¤ ì´ˆê¸°í™”
            await self.vector_index.setup()
            await self.bm25_index.setup()
            
            # í•˜ì´ë¸Œë¦¬ë“œ ë¦¬íŠ¸ë¦¬ë²„ ìƒì„±
            self.hybrid_retriever = CodeHybridRetriever(
                vector_index=self.vector_index,
                bm25_index=self.bm25_index,
                vector_weight=self.config.get('vector_weight', 0.7),
                bm25_weight=self.config.get('bm25_weight', 0.3),
                use_rrf=self.config.get('use_rrf', True),
                rrf_k=self.config.get('rrf_k', 60),
                max_results=self.config.get('max_results', 50)
            )
            
            self._initialized = True
            logger.info("í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def retrieve(
        self, 
        query: str, 
        limit: int = 10,
        **kwargs
    ) -> List[RetrievalResult]:
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤í–‰"""
        await self.setup()
        
        start_time = time.time()
        
        try:
            # QueryBundle ìƒì„±
            query_bundle = QueryBundle(query_str=query)
            
            # ê²€ìƒ‰ ì‹¤í–‰
            nodes_with_scores = self.hybrid_retriever._retrieve(query_bundle)
            
            # RetrievalResultë¡œ ë³€í™˜
            results = []
            for node_with_score in nodes_with_scores[:limit]:
                node = node_with_score.node
                result = RetrievalResult(
                    id=node.id_,
                    content=node.text,
                    metadata=node.metadata,
                    score=node_with_score.score,
                    source="hybrid"
                )
                results.append(result)
            
            end_time = time.time()
            search_time = int((end_time - start_time) * 1000)
            
            logger.info(f"í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼, {search_time}ms")
            
            return results
            
        except Exception as e:
            logger.error(f"í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    async def search_with_detailed_scores(
        self,
        query: str,
        limit: int = 10,
        vector_weight: float = None,
        bm25_weight: float = None,
        use_rrf: bool = None,
        rrf_k: int = None
    ) -> Dict[str, Any]:
        """ìƒì„¸ ì ìˆ˜ì™€ í•¨ê»˜ ê²€ìƒ‰"""
        await self.setup()
        
        # ì„ì‹œë¡œ ì„¤ì • ë³€ê²½
        original_config = {}
        if vector_weight is not None:
            original_config['vector_weight'] = self.hybrid_retriever.vector_weight
            self.hybrid_retriever.vector_weight = vector_weight
        
        if bm25_weight is not None:
            original_config['bm25_weight'] = self.hybrid_retriever.bm25_weight
            self.hybrid_retriever.bm25_weight = bm25_weight
        
        if use_rrf is not None:
            original_config['use_rrf'] = self.hybrid_retriever.use_rrf
            self.hybrid_retriever.use_rrf = use_rrf
        
        if rrf_k is not None:
            original_config['rrf_k'] = self.hybrid_retriever.rrf_k
            self.hybrid_retriever.rrf_k = rrf_k
        
        try:
            start_time = time.time()
            
            # ê°œë³„ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ì§‘
            vector_results = await self.vector_index.search_with_scores(query, limit=50)
            bm25_results = await self.bm25_index.search_with_scores(query, limit=50)
            
            # ê²°í•© ê²°ê³¼ ê³„ì‚°
            if self.hybrid_retriever.use_rrf:
                combined_results = self.hybrid_retriever.scoring_strategy.reciprocal_rank_fusion(
                    vector_results, bm25_results, self.hybrid_retriever.rrf_k
                )
            else:
                combined_results = self.hybrid_retriever.scoring_strategy.weighted_average(
                    vector_results, bm25_results,
                    self.hybrid_retriever.vector_weight, self.hybrid_retriever.bm25_weight
                )
            
            end_time = time.time()
            search_time = int((end_time - start_time) * 1000)
            
            return {
                "query": query,
                "results": combined_results[:limit],
                "search_metadata": {
                    "vector_results_count": len(vector_results),
                    "bm25_results_count": len(bm25_results),
                    "combined_results_count": len(combined_results),
                    "search_time_ms": search_time,
                    "scoring_method": "rrf" if self.hybrid_retriever.use_rrf else "weighted",
                    "vector_weight": self.hybrid_retriever.vector_weight,
                    "bm25_weight": self.hybrid_retriever.bm25_weight,
                    "rrf_k": self.hybrid_retriever.rrf_k if self.hybrid_retriever.use_rrf else None
                },
                "individual_results": {
                    "vector": vector_results[:10],
                    "bm25": bm25_results[:10]
                }
            }
            
        finally:
            # ì›ë˜ ì„¤ì • ë³µì›
            for key, value in original_config.items():
                setattr(self.hybrid_retriever, key, value)
    
    async def compare_scoring_methods(
        self,
        query: str,
        limit: int = 10
    ) -> Dict[str, Any]:
        """ìŠ¤ì½”ì–´ë§ ë°©ë²• ë¹„êµ"""
        await self.setup()
        
        # Vectorì™€ BM25 ê°œë³„ ê²°ê³¼
        vector_results = await self.vector_index.search_with_scores(query, limit=50)
        bm25_results = await self.bm25_index.search_with_scores(query, limit=50)
        
        # ê°€ì¤‘í‰ê·  ê²°ê³¼
        weighted_results = self.hybrid_retriever.scoring_strategy.weighted_average(
            vector_results, bm25_results, 0.7, 0.3
        )
        
        # RRF ê²°ê³¼
        rrf_results = self.hybrid_retriever.scoring_strategy.reciprocal_rank_fusion(
            vector_results, bm25_results, 60
        )
        
        return {
            "query": query,
            "comparison": {
                "vector_only": vector_results[:limit],
                "bm25_only": bm25_results[:limit],
                "weighted_fusion": weighted_results[:limit],
                "rrf_fusion": rrf_results[:limit]
            },
            "statistics": {
                "vector_unique": len(set(r['id'] for r in vector_results)),
                "bm25_unique": len(set(r['id'] for r in bm25_results)),
                "overlap": len(set(r['id'] for r in vector_results) & 
                             set(r['id'] for r in bm25_results))
            }
        }
    
    async def teardown(self) -> None:
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if self.vector_index:
            await self.vector_index.teardown()
        if self.bm25_index:
            # BM25 indexëŠ” íŠ¹ë³„í•œ ì •ë¦¬ê°€ í•„ìš” ì—†ì„ ìˆ˜ ìˆìŒ
            pass
```

### 2. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìµœì í™”

```python
# app/retriever/hybrid_optimizer.py
from typing import List, Dict, Any, Optional, Tuple
import numpy as np
from sklearn.metrics import ndcg_score
import logging

logger = logging.getLogger(__name__)

class HybridSearchOptimizer:
    """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìµœì í™”"""
    
    def __init__(self, retrieval_service):
        self.retrieval_service = retrieval_service
        self.evaluation_data = []
    
    async def optimize_weights(
        self,
        evaluation_queries: List[Dict[str, Any]],
        weight_range: Tuple[float, float] = (0.1, 0.9),
        step: float = 0.1
    ) -> Dict[str, Any]:
        """ê°€ì¤‘ì¹˜ ìµœì í™”"""
        best_weights = None
        best_score = 0.0
        results = []
        
        vector_weights = np.arange(weight_range[0], weight_range[1] + step, step)
        
        for vector_weight in vector_weights:
            bm25_weight = 1.0 - vector_weight
            
            total_ndcg = 0.0
            valid_queries = 0
            
            for query_data in evaluation_queries:
                query = query_data['query']
                relevant_docs = query_data.get('relevant_docs', [])
                
                if not relevant_docs:
                    continue
                
                # ê²€ìƒ‰ ì‹¤í–‰
                search_result = await self.retrieval_service.search_with_detailed_scores(
                    query=query,
                    limit=20,
                    vector_weight=vector_weight,
                    bm25_weight=bm25_weight,
                    use_rrf=False
                )
                
                # NDCG ê³„ì‚°
                ndcg = self._calculate_ndcg(
                    search_result['results'], 
                    relevant_docs
                )
                
                if ndcg is not None:
                    total_ndcg += ndcg
                    valid_queries += 1
            
            if valid_queries > 0:
                avg_ndcg = total_ndcg / valid_queries
                results.append({
                    'vector_weight': round(vector_weight, 2),
                    'bm25_weight': round(bm25_weight, 2),
                    'avg_ndcg': round(avg_ndcg, 4),
                    'evaluated_queries': valid_queries
                })
                
                if avg_ndcg > best_score:
                    best_score = avg_ndcg
                    best_weights = (vector_weight, bm25_weight)
        
        return {
            'best_weights': {
                'vector_weight': best_weights[0] if best_weights else 0.7,
                'bm25_weight': best_weights[1] if best_weights else 0.3
            },
            'best_score': best_score,
            'all_results': results,
            'optimization_summary': {
                'total_weight_combinations': len(results),
                'best_combination': best_weights,
                'improvement_from_default': best_score - self._get_default_score(results)
            }
        }
    
    async def optimize_rrf_k(
        self,
        evaluation_queries: List[Dict[str, Any]],
        k_range: Tuple[int, int] = (10, 100),
        step: int = 10
    ) -> Dict[str, Any]:
        """RRF K íŒŒë¼ë¯¸í„° ìµœì í™”"""
        best_k = None
        best_score = 0.0
        results = []
        
        k_values = range(k_range[0], k_range[1] + step, step)
        
        for k in k_values:
            total_ndcg = 0.0
            valid_queries = 0
            
            for query_data in evaluation_queries:
                query = query_data['query']
                relevant_docs = query_data.get('relevant_docs', [])
                
                if not relevant_docs:
                    continue
                
                # RRFë¡œ ê²€ìƒ‰ ì‹¤í–‰
                search_result = await self.retrieval_service.search_with_detailed_scores(
                    query=query,
                    limit=20,
                    use_rrf=True,
                    rrf_k=k
                )
                
                # NDCG ê³„ì‚°
                ndcg = self._calculate_ndcg(
                    search_result['results'],
                    relevant_docs
                )
                
                if ndcg is not None:
                    total_ndcg += ndcg
                    valid_queries += 1
            
            if valid_queries > 0:
                avg_ndcg = total_ndcg / valid_queries
                results.append({
                    'rrf_k': k,
                    'avg_ndcg': round(avg_ndcg, 4),
                    'evaluated_queries': valid_queries
                })
                
                if avg_ndcg > best_score:
                    best_score = avg_ndcg
                    best_k = k
        
        return {
            'best_rrf_k': best_k or 60,
            'best_score': best_score,
            'all_results': results
        }
    
    def _calculate_ndcg(
        self, 
        search_results: List[Dict[str, Any]], 
        relevant_docs: List[str],
        k: int = 10
    ) -> Optional[float]:
        """NDCG ì ìˆ˜ ê³„ì‚°"""
        if not search_results or not relevant_docs:
            return None
        
        # ê²€ìƒ‰ ê²°ê³¼ì˜ ê´€ë ¨ì„± ì ìˆ˜ ìƒì„±
        relevance_scores = []
        for result in search_results[:k]:
            doc_id = result['id']
            if doc_id in relevant_docs:
                # ê´€ë ¨ ë¬¸ì„œë©´ 1, ì•„ë‹ˆë©´ 0
                relevance_scores.append(1)
            else:
                relevance_scores.append(0)
        
        if sum(relevance_scores) == 0:
            return 0.0
        
        # NDCG ê³„ì‚°
        try:
            # sklearnì˜ ndcg_scoreëŠ” 2D ë°°ì—´ì„ ìš”êµ¬
            y_true = np.array([relevance_scores])
            y_score = np.array([[result['combined_score'] for result in search_results[:k]]])
            
            return ndcg_score(y_true, y_score, k=k)
        except Exception as e:
            logger.warning(f"NDCG ê³„ì‚° ì‹¤íŒ¨: {e}")
            return None
    
    def _get_default_score(self, results: List[Dict[str, Any]]) -> float:
        """ê¸°ë³¸ ê°€ì¤‘ì¹˜(0.7, 0.3)ì˜ ì ìˆ˜ ì°¾ê¸°"""
        for result in results:
            if (abs(result['vector_weight'] - 0.7) < 0.01 and 
                abs(result['bm25_weight'] - 0.3) < 0.01):
                return result['avg_ndcg']
        return 0.0
```

## âœ… ì™„ë£Œ ì¡°ê±´

1. **Hybrid Retriever êµ¬í˜„**: LlamaIndex BaseRetriever ê¸°ë°˜ìœ¼ë¡œ ì™„ì „íˆ êµ¬í˜„ë¨
2. **ìŠ¤ì½”ì–´ë§ ì „ëµ**: RRFì™€ ê°€ì¤‘í‰ê·  ë‘ ê°€ì§€ ë°©ë²• ëª¨ë‘ ì§€ì›ë¨
3. **ë³‘ë ¬ ê²€ìƒ‰**: Vectorì™€ BM25 ê²€ìƒ‰ì´ ë³‘ë ¬ë¡œ ì‹¤í–‰ë¨
4. **ê²°ê³¼ ê²°í•©**: ë‘ ê²€ìƒ‰ ê²°ê³¼ê°€ íš¨ê³¼ì ìœ¼ë¡œ ê²°í•©ë¨
5. **ì„±ëŠ¥ ìµœì í™”**: ëŒ€ìš©ëŸ‰ ê²€ìƒ‰ ì‹œ ì„±ëŠ¥ì´ ì–‘í˜¸í•¨
6. **íŒŒë¼ë¯¸í„° ì¡°ì •**: ê°€ì¤‘ì¹˜ì™€ RRF Kê°’ ìµœì í™” ì§€ì›ë¨
7. **í‰ê°€ ì‹œìŠ¤í…œ**: ê²€ìƒ‰ í’ˆì§ˆ í‰ê°€ ë„êµ¬ ì œê³µë¨

## ğŸ“‹ ë‹¤ìŒ Taskì™€ì˜ ì—°ê´€ê´€ê³„

- **Task 13**: LangChain PromptTemplateì—ì„œ ê²€ìƒ‰ ê²°ê³¼ í™œìš©
- **Task 15**: HybridRAG ì„œë¹„ìŠ¤ì—ì„œ ì´ Retrieverë¥¼ í•µì‹¬ êµ¬ì„±ìš”ì†Œë¡œ ì‚¬ìš©

## ğŸ§ª í…ŒìŠ¤íŠ¸ ê³„íš

```python
# tests/unit/retriever/test_hybrid_retriever.py
async def test_hybrid_retriever_setup():
    """Hybrid Retriever ì„¤ì • í…ŒìŠ¤íŠ¸"""
    service = HybridRetrievalService(vector_index, bm25_index)
    await service.setup()
    assert service._initialized is True

async def test_parallel_search():
    """ë³‘ë ¬ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
    retriever = CodeHybridRetriever(vector_index, bm25_index)
    vector_results, bm25_results = await retriever._parallel_search("authentication")
    assert isinstance(vector_results, list)
    assert isinstance(bm25_results, list)

async def test_weighted_scoring():
    """ê°€ì¤‘í‰ê·  ìŠ¤ì½”ì–´ë§ í…ŒìŠ¤íŠ¸"""
    vector_results = [{'id': '1', 'score': 0.8, 'content': 'test', 'metadata': {}}]
    bm25_results = [{'id': '1', 'score': 0.6, 'content': 'test', 'metadata': {}}]
    
    combined = HybridScoringStrategy.weighted_average(
        vector_results, bm25_results, 0.7, 0.3
    )
    
    assert len(combined) == 1
    assert combined[0]['combined_score'] == 0.8 * 0.7 + 0.6 * 0.3

async def test_rrf_scoring():
    """RRF ìŠ¤ì½”ì–´ë§ í…ŒìŠ¤íŠ¸"""
    vector_results = [{'id': '1', 'score': 0.8, 'content': 'test', 'metadata': {}}]
    bm25_results = [{'id': '1', 'score': 0.6, 'content': 'test', 'metadata': {}}]
    
    combined = HybridScoringStrategy.reciprocal_rank_fusion(
        vector_results, bm25_results, k=60
    )
    
    assert len(combined) == 1
    assert 'rrf_score' in combined[0]
```

ì´ TaskëŠ” Vectorì™€ BM25 ê²€ìƒ‰ì˜ ì¥ì ì„ ê²°í•©í•˜ì—¬ ìµœê³  í’ˆì§ˆì˜ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì œê³µí•˜ëŠ” í•µì‹¬ êµ¬ì„±ìš”ì†Œì…ë‹ˆë‹¤. ì •êµí•œ ìŠ¤ì½”ì–´ë§ ì „ëµì„ í†µí•´ ì˜ë¯¸ì  ê²€ìƒ‰ê³¼ í‚¤ì›Œë“œ ê²€ìƒ‰ì˜ ì‹œë„ˆì§€ë¥¼ ê·¹ëŒ€í™”í•©ë‹ˆë‹¤. 